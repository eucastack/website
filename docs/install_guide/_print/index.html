<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.100.1"><link rel=canonical type=text/html href=https://www.eucastack.io/docs/install_guide/><link rel=alternate type=application/rss+xml href=https://www.eucastack.io/docs/install_guide/index.xml><meta name=robots content="noindex, nofollow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Installation Guide | EucaStack</title><meta name=description content="Installation Guide
This section describes concepts and tasks you need to successfully install Eucalyptus.
"><meta property="og:title" content="Installation Guide"><meta property="og:description" content="An open source AWS-compatible hybrid cloud powered by Eucalyptus"><meta property="og:type" content="website"><meta property="og:url" content="https://www.eucastack.io/docs/install_guide/"><meta property="og:site_name" content="EucaStack"><meta itemprop=name content="Installation Guide"><meta itemprop=description content="An open source AWS-compatible hybrid cloud powered by Eucalyptus"><meta name=twitter:card content="summary"><meta name=twitter:title content="Installation Guide"><meta name=twitter:description content="An open source AWS-compatible hybrid cloud powered by Eucalyptus"><link rel=preload href=/scss/main.min.dbc832a6b41f9cb352db274e4a5e4f9087c9f9f914bcd919a25e9dad92d530f3.css as=style><link href=/scss/main.min.dbc832a6b41f9cb352db274e4a5e4f9087c9f9f914bcd919a25e9dad92d530f3.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.6.0.min.js integrity=sha384-vtXRMe3mGCbOeY7l30aIg8H9p3GdeSe4IFlP6G8JMa7o7lXvnz3GFKzPxzJdPfGK crossorigin=anonymous></script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-00000000-0','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class=td-section><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar"><a class=navbar-brand href=/><span class=navbar-logo><svg viewBox="0 0 1388.9 333.38" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g transform="translate(-136.21 41.582)"><path transform="matrix(.26458 0 0 .26458 136.21 -41.582)" d="m1616.4 487.23c-38.46.0-73.324 9.8216-104.59 29.467s-55.615 47.177-73.047 82.594c-17.155 35.14-25.732 75.123-25.732 119.95v12.451c0 66.96 19.782 120.64 59.35 161.04 39.844 40.12 91.725 60.18 155.64 60.18 37.354.0 70.971-7.3314 100.85-21.996 30.16-14.941 54.232-35.833 72.217-62.672l-54.369-51.879c-29.053 37.354-66.683 56.029-112.89 56.029-32.926.0-60.319-10.791-82.178-32.373-21.582-21.582-33.896-50.911-36.939-87.988h293.43v-40.674c0-71.387-16.741-126.59-50.221-165.6-33.203-39.014-80.378-58.52-141.53-58.52zm927.61.0c-63.086.0-112.89 20.613-149.41 61.84-36.523 40.951-54.785 95.598-54.785 163.94v10.377c0 71.663 18.399 127.83 55.199 168.51 36.8 40.674 86.605 61.01 149.41 61.01 32.373.0 62.532-7.0547 90.478-21.166 27.946-14.111 50.081-33.203 66.406-57.275 16.325-24.349 25.042-50.497 26.148-78.443h-95.045c-1.1067 21.582-9.9609 39.706-26.562 54.371-16.602 14.665-37.491 21.996-62.67 21.996-33.203.0-58.659-11.898-76.367-35.693-17.432-24.072-26.148-60.456-26.148-109.15v-16.188c.2767-48.145 9.2702-83.975 26.978-107.49 17.708-23.796 42.887-35.695 75.537-35.695 25.456.0 46.345 8.3008 62.67 24.902 16.602 16.602 25.456 37.77 26.562 63.502h95.045c-1.6602-50.635-19.368-91.448-53.125-122.44-33.48-31.266-76.921-46.898-130.32-46.898zm439.94.0c-34.587.0-65.992 6.0872-94.215 18.262-27.946 12.174-50.081 29.053-66.406 50.635-16.325 21.305-24.486 44.271-24.486 68.896h100.85c0-17.708 7.3333-32.236 21.998-43.58 14.665-11.621 33.48-17.432 56.445-17.432 26.562.0 46.345 7.0566 59.35 21.168 13.004 13.835 19.508 32.373 19.508 55.615v29.469h-61.842c-66.13.0-117.04 12.865-152.73 38.598-35.417 25.456-53.125 62.118-53.125 109.99.0 37.907 14.251 69.727 42.75 95.459s65.299 38.598 110.4 38.598c46.484.0 85.775-16.739 117.87-50.219 3.3203 19.369 7.194 33.34 11.621 41.918h102.93v-7.0547c-11.344-24.072-17.018-56.308-17.018-96.705v-202.54c-.8301-47.868-16.878-84.945-48.144-111.23-31.266-26.563-73.184-39.844-125.76-39.844zm-1099.9 8.3008v290.94c0 53.955 12.451 95.182 37.354 123.68 25.179 28.499 62.118 42.748 110.82 42.748 54.508.0 96.566-17.432 126.17-52.295l2.4903 43.994h95.045v-449.07h-100.86v322.49c-17.155 35.14-50.221 52.709-99.195 52.709-47.314.0-70.971-28.499-70.971-85.498v-289.7h-100.86zm-268.12 72.631c27.946.0 49.805 8.7168 65.576 26.148 15.772 17.155 24.765 42.611 26.978 76.367v7.4707h-192.16c4.7038-34.587 15.495-61.563 32.373-80.932 17.155-19.369 39.567-29.055 67.236-29.055zm1386.6 165.6h54.371v84.668c-8.8542 16.325-22.135 29.329-39.844 39.014-17.432 9.6842-36.109 14.527-56.031 14.527-21.582.0-38.874-5.6732-51.879-17.018-12.728-11.621-19.092-27.116-19.092-46.484.0-23.796 9.4075-42.195 28.223-55.199 18.815-13.005 46.898-19.508 84.252-19.508z" fill="#fff"/><path transform="matrix(.26458 0 0 .26458 136.21 -41.582)" d="m4889.8 307.1v637.5h100.85V798.09l44.824-46.07 133.23 192.58h116.62l-184.69-261.89 166.85-187.18h-121.19l-124.1 139.87-31.543 39.43V307.11h-100.85zm-1162.1 79.271v109.16h-73.877v74.707h73.877v254.42c0 85.498 38.737 128.25 116.21 128.25 21.305.0 43.441-3.181 66.406-9.5449v-78.027c-11.898 2.7669-23.656 4.1504-35.277 4.1504-17.432.0-29.606-3.7364-36.523-11.207-6.6406-7.7474-9.9609-20.199-9.9609-37.354v-250.68h79.272v-74.707h-79.272v-109.16h-100.86zm-296.34 100.86c-50.358.0-91.862 13.005-124.51 39.014-32.65 26.009-48.975 58.382-48.975 97.119.0 46.208 25.179 81.487 75.537 105.84 22.965 11.068 51.602 20.199 85.912 27.393 34.31 7.194 58.798 15.495 73.463 24.902 14.942 9.4076 22.412 23.103 22.412 41.088.0 16.325-6.9174 29.606-20.752 39.844-13.835 9.9609-34.033 14.941-60.596 14.941-27.392.0-49.39-6.3639-65.992-19.092-16.602-13.005-25.593-31.404-26.977-55.199h-97.949c0 26.839 8.0241 51.879 24.072 75.121 16.048 23.242 38.46 41.504 67.236 54.785s61.563 19.922 98.363 19.922c54.232.0 98.088-12.451 131.57-37.354 33.48-25.179 50.221-57.966 50.221-98.363.0-24.072-5.5338-44.548-16.602-61.426-10.791-16.878-27.532-31.266-50.221-43.164-22.412-12.174-53.402-22.551-92.969-31.129-39.567-8.8542-65.853-17.569-78.857-26.146-13.005-8.5775-19.508-20.615-19.508-36.109.0-17.155 6.9173-30.852 20.752-41.09 14.112-10.238 32.236-15.355 54.371-15.355 23.795.0 42.887 6.5013 57.275 19.506 14.388 12.728 21.582 28.776 21.582 48.145h100.86c0-42.334-16.602-76.781-49.805-103.34-32.926-26.563-76.23-39.844-129.91-39.844zm733.79.0c-34.587.0-65.99 6.0872-94.213 18.262-27.946 12.174-50.081 29.053-66.406 50.635-16.325 21.305-24.488 44.271-24.488 68.896h100.86c0-17.708 7.3313-32.236 21.996-43.58 14.665-11.621 33.48-17.432 56.445-17.432 26.562.0 46.347 7.0566 59.352 21.168 13.005 13.835 19.506 32.373 19.506 55.615v29.469h-61.84c-66.13.0-117.04 12.865-152.73 38.598-35.417 25.456-53.125 62.118-53.125 109.99.0 37.907 14.249 69.727 42.748 95.459 28.499 25.732 65.3 38.598 110.4 38.598 46.484.0 85.775-16.739 117.87-50.219 3.3202 19.369 7.194 33.34 11.621 41.918h102.93v-7.0547c-11.344-24.072-17.016-56.308-17.016-96.705v-202.54c-.83-47.868-16.878-84.945-48.144-111.23-31.266-26.563-73.186-39.844-125.76-39.844zm464.84.0c-63.086.0-112.89 20.613-149.41 61.84-36.524 40.951-54.785 95.598-54.785 163.94v10.377c0 71.663 18.401 127.83 55.201 168.51 36.8 40.674 86.605 61.01 149.41 61.01 32.373.0 62.532-7.0547 90.479-21.166 27.946-14.111 50.081-33.203 66.406-57.275 16.325-24.349 25.042-50.497 26.148-78.443h-95.045c-1.1066 21.582-9.9608 39.706-26.562 54.371-16.601 14.665-37.493 21.996-62.672 21.996-33.203.0-58.659-11.898-76.367-35.693-17.432-24.072-26.146-60.456-26.146-109.15V711.36c.2769-48.145 9.2682-83.975 26.976-107.49 17.708-23.796 42.888-35.695 75.537-35.695 25.456.0 46.347 8.3008 62.672 24.902 16.602 16.602 25.456 37.77 26.562 63.502h95.045c-1.6602-50.635-19.37-91.448-53.127-122.44-33.48-31.266-76.921-46.898-130.32-46.898zm-446.17 246.53h54.369v84.668c-8.8541 16.325-22.135 29.329-39.844 39.014-17.432 9.6842-36.107 14.527-56.029 14.527-21.582.0-38.876-5.6732-51.881-17.018-12.728-11.621-19.092-27.116-19.092-46.484.0-23.796 9.4075-42.195 28.223-55.199 18.815-13.005 46.9-19.508 84.254-19.508z" fill="#8bc13a"/></g><g transform="translate(9.5814 7.9375)"><path transform="scale(.26458)" d="m560.34-22.102-558.42 231.31c-21.06 8.7235-38.133 34.275-38.133 57.07v688.09c0 11.398 8.5364 24.173 19.067 28.535l577.49 239.2c10.53 4.3617 27.603 4.3617 38.133.0l558.42-231.31c21.06-8.7235 38.133-34.275 38.133-57.07v-688.09c0-11.398-8.5364-24.173-19.067-28.535l-577.49-239.2c-10.53-4.3617-27.603-4.3617-38.133.0z" fill="#fff"/></g><g transform="translate(-1331.7 150.96)"><g transform="translate(-.13227 -.14313)"><path transform="scale(.26458)" d="m5651.4-517.82c-4.3107-.18795-9.0505.68347-14.025 2.7441l-507.35 210.15c-19.9 8.2427-36.031 32.385-36.031 53.924v642c0 11.537 4.7163 19.84 12.072 23.934v.06641l1.0156.41992c1.147.55934 2.2859 1.1151 3.5469 1.4688l116.15 48.111v-90l410.6-170.08c19.9-8.2427 36.031-32.385 36.031-53.924v-581l108.64 45v-80l-120.26-49.812c-3.0346-1.7765-6.523-2.8394-10.385-3.0078z" fill="#8bc13a"/><path d="m1379.7 116.68V-53.18c0-5.6989 4.2682-12.087 9.5333-14.268l134.24-55.602c5.2651-2.1809 9.5333.67105 9.5333 6.3699v169.86c0 5.6989-4.2682 12.087-9.5333 14.268l-134.24 55.602c-5.2651 2.1809-9.5333-.67105-9.5333-6.3699z" fill="#003556"/><path transform="scale(.26458)" d="m5856.6-432.82c-4.3107-.18795-9.0505.68347-14.025 2.7441l-507.35 210.15c-19.9 8.2427-36.031 32.385-36.031 53.924v642c0 11.536 4.7155 19.84 12.07 23.934v.06641l1.0352.42969c1.1397.55448 2.2713 1.1073 3.5234 1.459l116.15 48.111v-90l410.6-170.08c19.9-8.2427 36.031-32.385 36.031-53.924v-561l108.64 45v-1e2l-120.26-49.812c-3.0347-1.7765-6.525-2.8394-10.387-3.0078z" fill="#8bc13a"/><path d="m1434 139.17V-30.69c0-5.6989 4.2682-12.087 9.5333-14.268l134.24-55.602c5.2651-2.1809 9.5333.67105 9.5333 6.3699v169.86c0 5.6989-4.2682 12.087-9.5333 14.268l-134.24 55.602c-5.2651 2.1809-9.5333-.67105-9.5333-6.3699z" fill="#003556"/><path transform="scale(.26458)" d="m6061.8-347.82c-4.3107-.18795-9.0505.68347-14.025 2.7441l-507.35 210.15c-19.9 8.2427-36.031 32.385-36.031 53.924v642c1e-4 11.537 4.7163 19.84 12.072 23.934v.06641l1.0156.41992c1.147.55934 2.2859 1.1151 3.5469 1.4688l116.15 48.111v-90l410.6-170.08c19.9-8.2427 36.031-32.385 36.031-53.924v-561l108.64 45v-1e2l-120.25-49.811c-3.036-1.7784-6.5287-2.8413-10.393-3.0098z" fill="#8bc13a"/><path d="m1488.3 161.66v-169.86c0-5.6989 4.2682-12.087 9.5333-14.268l134.24-55.602c5.2651-2.1809 9.5333.67105 9.5333 6.3699v169.86c0 5.6989-4.2682 12.087-9.5333 14.268l-134.24 55.602c-5.2651 2.1809-9.5333-.67105-9.5333-6.3699z" fill="#003556"/><path d="m1520.2-14.532 89.523-37.082c5.2651-2.1809 9.5333.67105 9.5333 6.3699v135.47c0 5.6989-4.2682 12.087-9.5333 14.268l-89.523 37.082c-5.2651 2.1809-9.5333-.67104-9.5333-6.3699v-135.47c0-5.6989 4.2682-12.087 9.5333-14.268z" fill="#fff"/><path d="m1596.9 85.99-63.876 26.458-1e-4-46.302 49.504-20.505V29.766l-49.504 20.505 1e-4-46.302 63.876-26.458z" fill="#8bc13a"/></g></g></svg></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/docs/><i class='fas fa-book'></i><span class=active>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/blog/><i class='fas fa-rss'></i><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/community/><i class='fas fa-users'></i><span>Community</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"><input type=search class="form-control td-search-input" placeholder="&#xf002; Search this site…" aria-label="Search this site…" autocomplete=off></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main><div class=td-content><div class="pageinfo pageinfo-primary d-print-none"><p>This is the multi-page printable view of this section.
<a href=# onclick="return print(),!1">Click here to print</a>.</p><p><a href=/docs/install_guide/>Return to the regular view of this page</a>.</p></div><h1 class=title>Installation Guide</h1><ul><li>1: <a href=#pg-1982a068fa7e47f88783f4d54cb5d003>Installation Overview</a></li><ul></ul><li>2: <a href=#pg-6d78406d918bd7894025c1743b526546>Introduction to Eucalyptus</a></li><ul><li>2.1: <a href=#pg-de069bf8912ac64065ebcab85c7461f3>Eucalyptus Overview</a></li><ul></ul><li>2.2: <a href=#pg-23a4f3e33ed01dedee5d6356fc8830b7>Eucalyptus Components</a></li><ul></ul><li>2.3: <a href=#pg-57cacd852b34aa702681badd617fa5c5>System Requirements</a></li><ul></ul></ul><li>3: <a href=#pg-e01281a8db4910fb78f0d12ffd65afe0>Automated Eucalyptus Installation</a></li><ul></ul><li>4: <a href=#pg-12bc0a87fc6f085bd8de2b8681be810a>Manual Eucalyptus Installation</a></li><ul><li>4.1: <a href=#pg-b7604a899f9379e2a4ad64b89548b5a3>Plan Your Installation</a></li><ul><li>4.1.1: <a href=#pg-0462e0983621e9e80df8057a5f87089e>Eucalyptus Architecture Overview</a></li><ul></ul><li>4.1.2: <a href=#pg-c57095c343881511c6992288161bb07d>Plan Your Hardware</a></li><ul></ul><li>4.1.3: <a href=#pg-e6dc0ef0fcec95ccdc99df75bd2c99f8>Plan Services Placement</a></li><ul></ul><li>4.1.4: <a href=#pg-447c3fba4a65cbe021e473fffd22ce9d>Plan Disk Space</a></li><ul></ul><li>4.1.5: <a href=#pg-3a0799333f9d078659c0417ef1a1bc02>Plan Eucalyptus Features</a></li><ul><li>4.1.5.1: <a href=#pg-1abf120cbe2ad01da294a3af9af82b16>Availability Zone Support</a></li><ul></ul><li>4.1.5.2: <a href=#pg-c67311d13adefe1c703c24414718c35f>Object Storage</a></li><ul></ul></ul><li>4.1.6: <a href=#pg-d4b6f38707425e1c71a4e9bf6b20026f>Plan Networking Modes</a></li><ul><li>4.1.6.1: <a href=#pg-9e803e1e2ff2aef49d537ffcdab263e0>About Eucanetd</a></li><ul></ul><li>4.1.6.2: <a href=#pg-4a09021661db136481b10bdbcfcadf33>Understanding Eucalyptus EDGE Mode</a></li><ul></ul><li>4.1.6.3: <a href=#pg-89eeb5c8d44418651392426591292fef>Understanding VPCMIDO and MidoNet</a></li><ul></ul></ul><li>4.1.7: <a href=#pg-a2181acdf80f6af185740ebc8fad10a0>Prepare the Network</a></li><ul><li>4.1.7.1: <a href=#pg-09ac412868e7569242d53b81dd90e21f>Reserve Ports</a></li><ul></ul><li>4.1.7.2: <a href=#pg-f79af8966d6daed045469c4cbf231034>Verify Connectivity</a></li><ul></ul></ul></ul><li>4.2: <a href=#pg-7445d721146b3bd901e55ec91ae81aa4>Configure Dependencies</a></li><ul><li>4.2.1: <a href=#pg-6cefa559970e018b0616595a7b88f9d3>Configure Bridges</a></li><ul></ul><li>4.2.2: <a href=#pg-df5626afcae9a08fe87ee2b7a8bdf8ce>Disable FirewallD on RHEL 7</a></li><ul></ul><li>4.2.3: <a href=#pg-1cd6ada50e0e7b78b2d90f4603c34345>Configure NTP</a></li><ul></ul><li>4.2.4: <a href=#pg-b492735f6bd0619b5a487201a17fedcc>Configure Java</a></li><ul></ul><li>4.2.5: <a href=#pg-eca124ba6897a9d471807816d50dc50d>Configure an MTA</a></li><ul></ul><li>4.2.6: <a href=#pg-d116f8746c016eeb95e02cf25d69dc9b>Install MidoNet</a></li><ul><li>4.2.6.1: <a href=#pg-5bb925d2c296c64558ffa27487ecb1a6>Prerequisites</a></li><ul></ul><li>4.2.6.2: <a href=#pg-5002f76f28ab24c82d06601830a8d53a>MidoNet Component Topology</a></li><ul></ul><li>4.2.6.3: <a href=#pg-b670fbdd76e9d8c060bb6a50218a5226>Install MidoNet for Eucalyptus</a></li><ul></ul></ul></ul><li>4.3: <a href=#pg-671d5e1abc09d2e7bfe7ddbd6dde02d9>Install Repositories</a></li><ul><li>4.3.1: <a href=#pg-0b4fcc2c7d167b279883e39950e226b6>Software Signing</a></li><ul></ul><li>4.3.2: <a href=#pg-90008be4c92c3bb568e4cc25e4c50356>Install Eucalyptus Release Packages</a></li><ul></ul></ul><li>4.4: <a href=#pg-44973e6bf96612bed4bcbdfbd9a7fd95>Configure Eucalyptus</a></li><ul><li>4.4.1: <a href=#pg-14155a79410525e50ff553116b98f68e>Configure SELinux</a></li><ul></ul><li>4.4.2: <a href=#pg-b207cc52541e5c29799b86402eba76bf>Configure Network Modes</a></li><ul><li>4.4.2.1: <a href=#pg-a2a9c18fa398c16422822d97110e4c38>Configure EDGE Network Mode</a></li><ul></ul><li>4.4.2.2: <a href=#pg-8a92c056ba1bcd9ef177398b6531e644>Configure VPCMIDO Network Mode</a></li><ul><li>4.4.2.2.1: <a href=#pg-f8ba73af96d5cbb99b41ddffed1ee80e>VPCMIDO Gateway Configuration Parameters</a></li><ul></ul></ul></ul><li>4.4.3: <a href=#pg-4a69989b840665db85b061db956b4cb4>Create Scheduling Policy</a></li><ul></ul></ul><li>4.5: <a href=#pg-5ae0c9c8d53a01fedd24bb294ad33591>Start Eucalyptus</a></li><ul><li>4.5.1: <a href=#pg-e5e8324b00fdfa50dcd59ddbf6f60ddb>Start the CLC</a></li><ul></ul><li>4.5.2: <a href=#pg-e52984760577000fde6160fd154cc81e>Start the UFS</a></li><ul></ul><li>4.5.3: <a href=#pg-914aa1501b6ef1bcbb0e19230cf43590>Start Walrus</a></li><ul></ul><li>4.5.4: <a href=#pg-fba34cb1eb8eead504cd60172f4a0f09>Start the CC</a></li><ul></ul><li>4.5.5: <a href=#pg-f56ccb1e4b8ad50651edc72cca7ba09d>Start the SC</a></li><ul></ul><li>4.5.6: <a href=#pg-a2992fd0511e4cd5b3e30621ca66c715>Start the NC</a></li><ul></ul><li>4.5.7: <a href=#pg-42ad0538f40eb9fe89a3ea0967ab4d80>Start the Management Console</a></li><ul></ul><li>4.5.8: <a href=#pg-e7dfbf0222ff21863a7a57492266c6d4>Verify the Startup</a></li><ul></ul></ul><li>4.6: <a href=#pg-108e0ca8c7851c5668e3b09f56eae60e>Register Eucalyptus Services</a></li><ul><li>4.6.1: <a href=#pg-6c3b799939e318d49db2499a7bd58541>Register User-Facing Services</a></li><ul></ul><li>4.6.2: <a href=#pg-0333fa64f2ebc68bd3e0ed029d46c621>Register the Walrus Backend</a></li><ul></ul><li>4.6.3: <a href=#pg-04341adcb357c8048563067bfaf9e9fd>Register the Cluster Controller</a></li><ul></ul><li>4.6.4: <a href=#pg-a4d7a5b8052a5795166ed717511322d1>Register the Storage Controller</a></li><ul></ul><li>4.6.5: <a href=#pg-df7fcaa99d87b06e61625e4a49b721de>Register the Node Controllers</a></li><ul></ul></ul><li>4.7: <a href=#pg-9f6ef2abc861228ad98d0746a52e3bbf>Configure the Runtime Environment</a></li><ul><li>4.7.1: <a href=#pg-a0ef37a70072d465efc415fbe578fa67>Configure Eucalyptus DNS</a></li><ul></ul><li>4.7.2: <a href=#pg-09d0cc0a79d201e09f5c9804c4c61cd3>Create the Eucalyptus Cloud Administrator User</a></li><ul></ul><li>4.7.3: <a href=#pg-dc4447570e8060e614e4b8d90b23a14c>Upload the Network Configuration</a></li><ul></ul><li>4.7.4: <a href=#pg-fd3ae2688dc91115bc710364761b2ce5>Configure Eucalyptus Storage</a></li><ul><li>4.7.4.1: <a href=#pg-a6a6c7da8c6d5461dad3100d9ba3e31c>Configure Block Storage</a></li><ul><li>4.7.4.1.1: <a href=#pg-aa18b8d819fd6a67cb70f4fa0d18328b>Use Ceph-RBD</a></li><ul><li>4.7.4.1.1.1: <a href=#pg-30efcc5250832311a0363dcab5fce14e>Configure Hypervisor Support for Ceph-RBD</a></li><ul></ul></ul><li>4.7.4.1.2: <a href=#pg-3545c566a3fc5b961cdc7b265f1876ce>About the BROKEN State</a></li><ul></ul><li>4.7.4.1.3: <a href=#pg-07723a85c687e2a440a2f0f6cefdfba9>Use Direct Attached Storage (JBOD)</a></li><ul></ul><li>4.7.4.1.4: <a href=#pg-8aef961027c14d30b9d6272cd4fd35d4>Use the Overlay Local Filesystem</a></li><ul></ul></ul><li>4.7.4.2: <a href=#pg-25aafdcb9e624a1e783a00453ac2ce31>Configure Object Storage</a></li><ul><li>4.7.4.2.1: <a href=#pg-06a4664ccf8870894a6bb96a526ff06f>Use Ceph-RGW</a></li><ul></ul><li>4.7.4.2.2: <a href=#pg-84f727ca46a827f083dac6dafc1dba25>Use MinIO Backend</a></li><ul></ul><li>4.7.4.2.3: <a href=#pg-bfe6a73803221ee955acb39011736fbe>Use Walrus Backend</a></li><ul></ul></ul></ul><li>4.7.5: <a href=#pg-88c36c1a825c683df6b9c36b64b2ad63>Install and Configure the Imaging Service</a></li><ul></ul><li>4.7.6: <a href=#pg-ebb91e7b9d56062f2a00522894fe0965>Configure the Load Balancer</a></li><ul></ul><li>4.7.7: <a href=#pg-d2c8e2a6f2f469cba2014a65b5ab8768>Configure Node Controller</a></li><ul></ul></ul></ul><li>5: <a href=#pg-18cc942116b7be0a5dd971348caeb9f8>Client Installation</a></li><ul><li>5.1: <a href=#pg-8cea5def468485a152ffc86adafe42ca>AWS CLI Installation</a></li><ul></ul><li>5.2: <a href=#pg-a6359d685c4cda87190983e9d9228cb1>Euca2ools Standalone Installation</a></li><ul></ul></ul><li>6: <a href=#pg-8515c0c3c3e0fe7882713abf9dd756c5>Find More Information</a></li><ul></ul></ul><div class=content><h1 id=installation-guide>Installation Guide</h1><p>This section describes concepts and tasks you need to successfully install Eucalyptus.</p></div></div><div class=td-content><h1 id=pg-1982a068fa7e47f88783f4d54cb5d003>1 - Installation Overview</h1><p>This topic helps you understand, plan for, and install Eucalyptus. If you follow the recommendations and instructions in this guide, you will have a working version of Eucalyptus customized for your specific needs and requirements. This guide walks you through installations for a few different use cases.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Upgrading to Eucalyptus version 5 from earlier versions is not currently supported.</div><p>You can choose from one of the installation types listed in the following table.</p><table><thead><tr><th style=text-align:left>What Do You Want to Do?</th><th style=text-align:left>Installation Type</th></tr></thead><tbody><tr><td style=text-align:left>Quickly deploy on one machine</td><td style=text-align:left>If you have a CentOS 7.9 minimal install and a few IP addresses to spare, try the FastStart script. Run the following command as root: bash &lt;(curl -Ls <a href=https://get.eucalyptus.cloud>https://get.eucalyptus.cloud</a>)</td></tr><tr><td style=text-align:left>Create a development or production environment</td><td style=text-align:left>See the <a href=/docs/install_guide/automated_install/>Automated Eucalyptus Installation</a> section for installation using Ansible</td></tr><tr><td style=text-align:left>Manually create a development or production environment</td><td style=text-align:left>See the <a href=/docs/install_guide/eucalyptus/>Manual Eucalyptus Installation</a> section for manual deployment steps</td></tr></tbody></table><p>We recommend that you read the section you choose in the order presented. To customize your installation, you have to understand what Eucalyptus is, what the installation requirements are, what your network configuration and restrictions are, and what Eucalyptus components and features are available based on your needs and requirements.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-6d78406d918bd7894025c1743b526546>2 - Introduction to Eucalyptus</h1><h1 id=introduction-to-eucalyptus>Introduction to Eucalyptus</h1><p>Eucalyptus is open source software for building AWS-compatible private and hybrid clouds.</p><p>As an Infrastructure as a Service (IaaS) product, Eucalyptus allows your users to provision your compute and storage resources on-demand.</p><p>You can install Eucalyptus on the following Linux distributions:</p><ul><li>CentOS 7.9</li><li>Red Hat Enterprise Linux (RHEL) 7.9</li></ul><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>References to RHEL in this guide apply equally to CentOS unless otherwise specified.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-de069bf8912ac64065ebcab85c7461f3>2.1 - Eucalyptus Overview</h1><p>Eucalyptus was designed to be easy to install and as non-intrusive as possible. The software framework is modular, with industry-standard, language-agnostic communication.</p><p>Eucalyptus provides a virtual network overlay that both isolates network traffic of different users and allows two or more clusters to appear to belong to the same Local Area Network (LAN). Also, Eucalyptus offers API compatibility with Amazon’s EC2, S3, IAM, ELB, Auto Scaling, CloudFormation, and CloudWatch services. This offers you the capability of a hybrid cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-23a4f3e33ed01dedee5d6356fc8830b7>2.2 - Eucalyptus Components</h1><p>This topic describes the various components that comprise a Eucalyptus cloud.The following image shows a high-level architecture of Eucalyptus with its main components.</p><p><img src=https://www.eucastack.io/images/euca_cloud_arch_basics.png alt=image>
A detailed description of each Eucalyptus component follows.</p><h2 id=cloud-controller>Cloud Controller</h2><p>In many deployments, the Cloud Controller (CLC) service and the User-Facing Services (UFS) are on the same host machine. This server is the entry-point into the cloud for administrators, developers, project managers, and end-users. The CLC handles persistence and is the backend for the UFS. A Eucalyptus cloud must have exactly one CLC.</p><h2 id=user-facing-services>User-Facing Services</h2><p>The User-Facing Services (UFS) serve as endpoints for the AWS-compatible services offered by Eucalyptus : EC2 (compute), AS (AutoScaling), CW (CloudWatch), ELB (LoadBalancing), IAM (Euare), and STS (tokens). A Eucalyptus cloud can have several UFS host machines.</p><h2 id=object-storage-gateway>Object Storage Gateway</h2><p>The Object Storage Gateway (OSG) is part of the UFS. The OSG passes requests to object storage providers and talks to the persistence layer (DB) to authenticate requests. You can use Walrus, Riak CS, or Ceph-RGW as the object storage provider.</p><h2 id=object-storage-provider>Object Storage Provider</h2><p>The Object Storage Provider (OSP) can be either the Eucalyptus Walrus backend, Riak CS, or Ceph-RGW. Walrus is intended for light S3 usage and is a single service. <a href=https://github.com/basho/riak>Riak</a> is an open source scalable general purpose data platform; it is intended for deployments with heavy S3 usage. Ceph-RGW is an object storage interface built on top of Librados.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4></div><h2 id=management-console>Management Console</h2><p>The Eucalyptus Management Console is an easy-to-use web-based interface that allows you to manage your Eucalyptus cloud. The Management Console is often deployed on the same host machine as the UFS. A Eucalyptus cloud can have multiple Management Console host machines.</p><h2 id=cluster-controller>Cluster Controller</h2><p>The Cluster Controller (CC) service must run on a host machine that has network connectivity to the host machines running the Node Controllers (NCs) and to the host machine for the CLC. CCs gather information about a set of NCs and schedules virtual machine (VM) execution on specific NCs. All NCs associated with a single CC must be in the same subnet.</p><h2 id=storage-controller>Storage Controller</h2><p>The Storage Controller (SC) service provides functionality similar to Amazon Elastic Block Store (Amazon EBS). The SC can interface with various storage systems. Elastic block storage exports storage volumes that can be attached by a VM and mounted or accessed as a raw block device. EBS volumes can persist past VM termination and are commonly used to store persistent data. An EBS volume cannot be shared between multiple VMs at once and can be accessed only within the same availability zone in which the VM is running. Users can create snapshots from EBS volumes. Snapshots are stored by the OSG and made available across availability zones.</p><h2 id=node-controller>Node Controller</h2><p>The Node Controller (NC) service runs on any machine that hosts VM instances. The NC controls VM activities, including the execution, inspection, and termination of VM instances. It also fetches and maintains a local cache of instance images, and it queries and controls the system software (host OS and the hypervisor) in response to queries and control requests from the CC.</p><h2 id=eucanetd>Eucanetd</h2><p>The eucanetd service implements artifacts to manage and define Eucalyptus cloud networking. Eucanetd runs alongside the CLC or NC services, depending on the configured networking mode.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-57cacd852b34aa702681badd617fa5c5>2.3 - System Requirements</h1><p>To install Eucalyptus, your system must meet the baseline requirements described in this topic.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The specific requirements of your deployment, including the number of physical machines, structure of the physical network, storage requirements, and access to software are ultimately determined by the features you choose for your cloud and the availability of infrastructure required to support those features.</div><h2 id=compute-requirements>Compute Requirements</h2><ul><li>Physical Machines: All services must be installed on physical servers, not virtual machines.</li><li>Central Processing Units (CPUs): We recommend that each host machine in your cloud contain either an Intel or AMD processor with a minimum of 4 2GHz cores.</li><li>Operating Systems: supports the following Linux distributions: CentOS 7.9 and RHEL 7.9. supports only 64-bit architecture.</li><li>Machine Clocks: Each host machine and any client machine clocks must be synchronized (for example, using NTP). These clocks must be synchronized all the time, not only during the installation process.</li></ul><h2 id=storage-and-memory-requirements>Storage and Memory Requirements</h2><ul><li>Each machine needs a minimum of 100GB of storage.</li><li>We recommend at least 500GB for Walrus and SC hosts.</li><li>We recommend 200GB per NC host running Linux VMs. Note that larger available disk space enables a greater number of VMs.</li><li>Each machine needs a minimum of 16GB RAM. However, we recommend more RAM for improved caching and on NCs to support more instances.</li></ul><h2 id=network-requirements>Network Requirements</h2><ul><li>For VPCMIDO, Eucalyptus needs MidoNet to be installed.</li><li>The network connecting machines that host components (except the CC and NC) must support UDP multicast for IP address 239.193.7.3. Note that UDP multicast is not used over the network that connects the CC to the NCs.</li></ul><p>Once you are satisfied that your systems requirements are met, you are ready to plan your Eucalyptus installation.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e01281a8db4910fb78f0d12ffd65afe0>3 - Automated Eucalyptus Installation</h1><p>Automated Eucalytpus installation uses an <a href=https://www.ansible.com/overview/how-ansible-works>Ansible</a> playbook.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Before starting the automated installation CentOS 7.9 should be installed on all hosts. RHEL is not currently supported for automated installs.</div><p>To install Eucalyptus you will need to have Ansible and the Eucalyptus playbooks available and to create an <em>inventory</em> file that describes your deployment.</p><h2 id=install-packages>Install Packages</h2><p>The host performing the installation must have the EPEL YUM repository available (for Ansible):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install epel-release
</span></span></code></pre></div><p>and a Eucalyptus YUM repository, either the release repository:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install https://downloads.eucalyptus.cloud/software/eucalyptus/5/rhel/7/x86_64/eucalyptus-release-5-1.11.as.el7.noarch.rpm
</span></span></code></pre></div><p>or the master repository for the latest nightly build:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install https://downloads.eucalyptus.cloud/software/eucalyptus/master/rhel/7/x86_64/eucalyptus-release-5-1.15.as.el7.noarch.rpm
</span></span></code></pre></div><h2 id=create-inventory>Create Inventory</h2><p>The Ansible inventory file describes both the hosts that will run your Eucalyptus cloud and the options for your installation.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#000>---</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>all</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud.example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>node[01:10].example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>vars</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>vpcmido_public_ip_range</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;1.X.Y.128-1.X.Y.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>vpcmido_public_ip_cidr</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;1.X.Y.128/25&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>children</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>cloud.example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>zone</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>cloud.example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>node</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>node[01:10].example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>There are three main sections to an inventory file:</p><ol><li><em>hosts</em> : the hosts to deploy</li><li><em>vars</em> : variables providing options for the deployment</li><li><em>children</em> : host groupings that describe where to install Eucalyptus components</li></ol><h3 id=minimal-install>Minimal Install</h3><p>The minimum inventory for a deployment must specify one host and have a <em>children</em>/<em>cloud</em> section that includes that host.</p><p>For <code>VPCMIDO</code> the <em>vars</em> for <em>vpcmido_public_ip_range</em> and <em>vpcmido_public_ip_cidr</em> must also be provided.</p><p>When the <em>zone</em> and <em>node</em> children are not specified they are assumed to be the same host as the <em>cloud</em>.</p><h3 id=customization>Customization</h3><p>Settings that are often used in an inventory are described in this section.</p><p>The DNS domain to be used should be set in the <em>vars</em> section:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_system_dns_dnsdomain</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;mycloud.example.com&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>The NTP server to use with services in your deployment can also be specifed:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_properties</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>services.imaging.worker.ntp_server</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;time.cloudflare.com&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>services.loadbalancing.worker.ntp_server</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;time.cloudflare.com&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The <em>cloud_properties</em> section allows you configure any settings that you would later set using <em>euctl</em></div><p>To specify region and zone names for your deployment add the <em>vars</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_region_name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;us-euca-1&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_zone_1_name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;us-euca-1a&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_zone_2_name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;us-euca-1b&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_zone_3_name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;us-euca-1c&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>You can follow AWS naming conventions or can use your own naming scheme. To specify which hosts belong to which zone update the <code>hosts</code> section:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>node01.example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>host_cluster_ipv4</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.10.101&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>host_public_ipv4</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;1.X.Y.101&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>host_zone_key</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>1</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>The <em>host_zone_key</em> value of <code>1</code> specifes that <code>node01</code> would be part of the <code>us-euca-1a</code> zone. This example also shows how to configure the public and cluster IP addresses for a host.</p><p>To specify the port for web sevices use:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_public_port</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#0000cf;font-weight:700>443</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>If using port <code>443</code> for web services, the management console should be deployed as a service to avoid a port conflict.</p><p>To enable a firewall on the public/cluster interfaces use:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_firewalld_configure</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>yes</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_firewalld_cluster_cidr</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0/16&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_firewalld_cluster_interface</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;en2&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_firewalld_public_interface</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;en1&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>Interfaces must be named consistently on all hosts.</p><p>The default install uses <em>overlay</em> for block storage, to use <em>das</em> you must have an LVM volume group available on all storage (<em>zone</em>) hosts and set:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_storage_dasdevice</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;storage_vg&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>To deploy the management console as service running on an instance in your Eucalyptus cloud:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>eucalyptus_console_cloud_deploy</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>yes</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>cloud_service_image_rpm</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>no</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>This will also create a DNS entry for the console such as <code>console.mycloud.example.com</code>. When deploying the console on an instance it is recommended to also set <em>cloud_service_image_rpm</em> to <code>no</code> so that the service image for loadbalancing and imaging is installed using the same approach rather than from the rpm.</p><h3 id=midonet-nsdb>MidoNet NSDB</h3><p>For <code>VPCMIDO</code> deployments the MidoNet NSDB (Network State Database) should be deployed on multiple hosts:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>midonet-nsdb</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>midonet-nsdb[01:03].example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>These could be distinct hosts, or could be hosts running cloud and zone components (for example)</p><h3 id=using-ceph>Using Ceph</h3><p>To use Ceph for block and object storage configure the settings:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ceph_release</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;nautilus&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ceph_osd_data_path</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;storage_vg/storage_lv&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ceph_public_network</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0/16&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>the <em>ceph_osd_data_path</em> should reference either an existing LVM volume available on all hosts or a device.</p><p>The hosts for ceph must be in the <em>ceph</em> group under <em>children</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ceph</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>      </span><span style=color:#204a87;font-weight:700>hosts</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>        </span><span style=color:#204a87;font-weight:700>ceph[01:03].example.com</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>There must be three or more hosts to have redundancy.</p><h3 id=using-minio>Using MinIO</h3><p>To deploy MinIO as the objectstorage provider you specify <em>minio</em> under <em>children</em>:</p><pre tabindex=0><code>    minio:
      hosts:
        minio.example.com:
</code></pre><p>This will deploy MinIO on those hosts and also configure MinIO as the objectstorage provider when Ceph is not being deployed. There must be three or more hosts to have redundancy.</p><h3 id=enabling-certbot-integration>Enabling Certbot Integration</h3><p>To enable <a href=https://letsencrypt.org>Let&rsquo;s Encrypt</a> for HTTPS via certbot set the following <em>vars</em>:</p><pre tabindex=0><code>    eucaconsole_certbot_configure: yes
    eucalyptus_console_certbot_enable: yes
    eucalyptus_services_certbot_enable: yes
</code></pre><p>To use this functionality the cloud must be public so that it can be reached for DNS (services) or HTTP (console) challenges. See the Let&rsquo;s Encrypt <a href=https://letsencrypt.org/docs/challenge-types/>Challenge Types</a> for details.</p><p>The <em>eucaconsole_certbot_configure</em> setting should be used when deploying the console on a physical host. The <em>eucalyptus_console_certbot_enable</em> setting applies when deploying the console on the cloud (i.e. when you specifed <em>eucalyptus_console_cloud_deploy</em>)</p><h2 id=test-connectivity>Test Connectivity</h2><p>Before starting a deployment, test that the installation host can access all hosts in the inventory by running:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ansible --inventory inventory.yml -m ping all
</span></span></code></pre></div><p>If this fails, ensure that you have configured SSH access to all inventory hosts (e.g. configure passwordless SSH access) before proceeding to the installation.</p><h2 id=perform-installation>Perform Installation</h2><p>To start a <code>VPCMIDO</code> installation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ansible-playbook --inventory inventory.yml /usr/share/eucalyptus-ansible/playbook_vpcmido.yml
</span></span></code></pre></div><p>To start an <code>EDGE</code> installation:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>ansible-playbook --inventory inventory.yml /usr/share/eucalyptus-ansible/playbook_edge.yml
</span></span></code></pre></div><p>See the <a href=https://www.eucastack.io/docs/install_guide/what_next/>Find More Information</a> page for next steps.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-12bc0a87fc6f085bd8de2b8681be810a>4 - Manual Eucalyptus Installation</h1><h1 id=manual-eucalyptus-installation>Manual Eucalyptus Installation</h1><p>This section details steps to install Eucalyptus manually. To install Eucalyptus, perform the following tasks in the order presented.</p><div class="alert alert-warning" role=alert><h4 class=alert-heading>Warning</h4>The recommended way to install Eucalyptus 5 is to follow the <a href=https://www.eucastack.io/docs/install_guide/automated_install/>Automated Eucalyptus Installation</a> section.</div></div><div class=td-content><h1 id=pg-b7604a899f9379e2a4ad64b89548b5a3>4.1 - Plan Your Installation</h1><h1 id=plan-your-installation>Plan Your Installation</h1><p>Before you install Eucalyptus components on your machines, we recommend that you take the time to plan how you want to install it.</p><p>To successfully plan for your Eucalyptus installation, you must determine two things:</p><ul><li>Think about the application workload performance and resource utilization tuning. Think about how many machines you want on your system.</li><li>Use your existing architecture and policies to determine the networking features you want to enable: EC2 Classic Networking or EC2 VPC Networking.</li></ul><p>This section describes how to evaluate each tradeoff to determine the best choice to make, and how to verify that the resource environment can support the features that are enabled as a consequence of making a choice.</p><p>By the end of this section, you should be able to specify how you will deploy Eucalyptus in your environment, any tradeoffs between feature set and flexibility, and where your deployment will integrate with existing infrastructure systems.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0462e0983621e9e80df8057a5f87089e>4.1.1 - Eucalyptus Architecture Overview</h1><p>This topics describes the relationship of the components in a Eucalyptus installation.
<img src=https://www.eucastack.io/images/euca_arch_separate_hosts.png alt=image>
The cloud components: Cloud Controller (CLC) and Walrus, as well as user components: User-Facing Services (UFS) and the Management Console, communicate with cluster components: the Cluster Controllers (CCs) and Storage Controllers (SCs). The CCs and SCs, in turn, communicate with the Node Controllers (NCs). The networks between machines hosting these components must be able to allow TCP connections between them.</p><p>Ceph provides an alternative to Walrus as an object storage provider, and can also be used as a block storage provider (EBS).</p></div><div class=td-content style=page-break-before:always><h1 id=pg-c57095c343881511c6992288161bb07d>4.1.2 - Plan Your Hardware</h1><p>This topic describes ways you can install Eucalyptus services on your physical servers.You can run Eucalyptus services in any combination on the various physical servers in a data center. For example, you can install the Cloud Controller (CLC), Walrus, CC, and SC on one host machine, and NCs on one or more host machines. Or you can install each service on an independent physical server. This gives each service its own local resources to work with.</p><p>Often in installation decisions, you must trade deployment simplicity for performance. For example, if you place all cloud (CLC) and zone (CC) services on a single machine, it makes for simple administration. This is because there is only one machine to monitor and control for the Eucalyptus control services. But, each service acts as an independent web service; so if they share a single machine, the reduced physical resources available to each service might become a performance bottleneck.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e6dc0ef0fcec95ccdc99df75bd2c99f8>4.1.3 - Plan Services Placement</h1><p><img src=https://www.eucastack.io/images/euca_deploy_examples_training_source.png alt=image></p><h2 id=cloud-services>Cloud Services</h2><p>The main decision for cloud services is whether to install the Cloud Controller (CLC) and Walrus on the same server. If they are on the same server, they operate as separate web services within a single Java environment, and they use a fast path for inter-service communication. If they are not on the same server, they use SOAP and REST to work together.</p><p>Sometimes the key factor for cloud services is not performance, but server cost and data center configuration. If you only have one server available for the cloud, then you have to install the services on the same server.</p><p>All services should be in the same data center. They use aggressive time-outs to maintain system responsiveness so separating them over a long-latency, lossy network link will not work.</p><h2 id=user-services>User Services</h2><p>The User Facing Services (UFS) handle all of the AWS APIs and provide an entry point for clients and users interacting with the Eucalyptus cloud. The UFS and the Management Console are often hosted on the same machine since both must be accessible from the public, client-facing network.</p><p>You may optionally choose to have redundant UFS and Management Console host machines behind a load balancer.</p><h2 id=zone-services>Zone Services</h2><p>The Eucalyptus services deployed in the zone level of a Eucalyptus deployment are the Cluster Controller (CC) and Storage Controller (SC).</p><p>You can install all zone services on a single server, or you can distribute them on different servers. The choice of one or multiple servers is dictated by the demands of user workload in terms of number of instances (CC) and EBS volume access (SC).</p><p>Things to consider for CC placement:</p><ul><li><p>Place the CC on a server that has TCP/IP connectivity to the front-end servers and the NC servers in its zone.</p></li><li><p>Each CC can manage a maximum of 4000 instances.
Things to consider for SC placement:</p></li><li><p>The SC host machine must always have TCP/IP connectivity to the CLC and be able use multicast to the CLC.</p></li><li><p>The SC must have TCP/IP connectivity to the UFS/OSG hosts for uploading snapshots into the object store. (The SC does not require connectivity directly to users, it is an internal component and does not serve user EBS API requests; that job is done by the UFS.)</p></li><li><p>The SC must be reachable via TCP/IP from all NCs in the zone within which the SC is registered. The SC and NC exchange tokens to authorize volume attachment, so they must be able to directly communicate. The SC provides the NCs with network access to the dynamic block volumes on the SC&rsquo;s storage (if the SC is configured for overlay local filesystem or DAS-JBOD).</p></li><li><p>IF using Ceph the SC must also have TCP/IP connectivity to the Ceph cluster.</p></li><li><p>If you are going to use overlay local filesystem or DAS-JBOD configurations to export local SC storage for EBS, then SC storage should consist of a fast, reliable disk pool (either local file-system or block-attached storage) so that the SC can create and maintain volumes for the NCs. The capacity of the disk pool should be sufficient to provide the NCs with enough space to accommodate all dynamic block volumes requests from end users.</p></li></ul><h2 id=node-services>Node Services</h2><p>The Node Controllers are the services that comprise the Eucalyptus backend. All NCs must have network connectivity to whatever machine(s) host their EBS volumes. Hosts are either a Ceph deployment or the SC.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-447c3fba4a65cbe021e473fffd22ce9d>4.1.4 - Plan Disk Space</h1><p>We recommend that you choose a disk for the Walrus that is large enough to hold all objects and buckets you ever expect to have, including all images that will ever be registered to your system, plus any Amazon S3 application data. For heavy S3 usage, Riak CS is a better choice for object storage.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>We recommend that you use LVM (Logical Volume Manager). If you run out of disk space, LVM allows you to add disks and migrate the data.</div><table><thead><tr><th style=text-align:left>Service</th><th style=text-align:left>Directory</th><th style=text-align:left>Minimum Size</th></tr></thead><tbody><tr><td style=text-align:left>Cloud Controller (CLC)CLC logging</td><td style=text-align:left>/var/lib/eucalyptus/db/var/log/eucalyptus</td><td style=text-align:left>20GB2GB</td></tr><tr><td style=text-align:left>WalrusWalrus logging</td><td style=text-align:left>/var/lib/eucalyptus/bukkits/var/log/eucalyptus</td><td style=text-align:left>250GB2GB</td></tr><tr><td style=text-align:left>Storage Controller (SC) (EBS storage) This disk space on the SC is only required if you are not using Ceph. For DAS the space must not be used by an existing filesystem.</td><td style=text-align:left>/var/lib/eucalyptus/volumes/var/log/eucalyptus</td><td style=text-align:left>250GB</td></tr><tr><td style=text-align:left>User-Facing Services (UFS)UFS logging</td><td style=text-align:left>/var/lib/eucalyptus/var/log/eucalyptus</td><td style=text-align:left>5GB 2GB</td></tr><tr><td style=text-align:left>Management ConsoleConsole logging</td><td style=text-align:left>/var/log/eucalyptus-console</td><td style=text-align:left>5GB 2GB</td></tr><tr><td style=text-align:left>Cluster Controller (CC)CC logging</td><td style=text-align:left>/var/lib/eucalyptus/CC/var/log/eucalyptus</td><td style=text-align:left>5GB2GB</td></tr><tr><td style=text-align:left>Node Controller (NC)NC logging</td><td style=text-align:left>/var/lib/eucalyptus/instances/var/log/eucalyptus</td><td style=text-align:left>250GB2GB</td></tr></tbody></table><p>If necessary, create symbolic links or mount points to larger filesystems from the above locations. Make sure that the &rsquo;eucalyptus&rsquo; user owns the directories.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3a0799333f9d078659c0417ef1a1bc02>4.1.5 - Plan Eucalyptus Features</h1><h1 id=plan-features>Plan Features</h1><p>Before you install Eucalyptus , we recommend that you think about the features you plan to implement with Eucalyptus. These features are detailed in the following sections.</p></div><div class=td-content><h1 id=pg-1abf120cbe2ad01da294a3af9af82b16>4.1.5.1 - Availability Zone Support</h1><p>Eucalyptus offers the ability to create multiple local availability zones.An availability zone for AWS denotes a large subset of their cloud environment. Eucalyptus refines this definition to denote a subset of the cloud that shares a local area network. Each Eucalyptus zone has its own Cluster Controller and Storage Controller.</p><p><img src=https://www.eucastack.io/images/euca-arch-basic-two-clusters.png alt=image></p></div><div class=td-content style=page-break-before:always><h1 id=pg-c67311d13adefe1c703c24414718c35f>4.1.5.2 - Object Storage</h1><p>Eucalyptus supports Walrus and Riak CS as its object storage backend. There is no extra planning if you use Walrus. If you use Riak CS, you can use a single Riak CS cluster for several Eucalyptus clouds. Basho (the vendor of RiakCS) recommends five nodes for each Riak CS cluster. This also means that you have to set up and configure a load balancer between the Riak CS nodes and the object storage gateway (OSG).</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d4b6f38707425e1c71a4e9bf6b20026f>4.1.6 - Plan Networking Modes</h1><h1 id=plan-networking-modes>Plan Networking Modes</h1><p>These networking modes are designed to allow you to choose an appropriate level of security and flexibility for your cloud. The purpose is to direct Eucalyptus to use different network features to manage the virtual networks that connect VMs to each other and to clients external to Eucalyptus .</p><p>Eucalyptus networking modes are generally modeled after AWS networking capabilities. In legacy AWS accounts, you have the ability to choose EC2 Classic network mode or VPC network mode. New AWS accounts do not have this flexibility and are forced into using VPC. Eucalyptus VPCMIDO mode is similar to AWS VPC in that it allows users to fully manage their cloud network, including the definition of a Classless Inter-Domain Routing (CIDR) block, subnets, and security groups with rules for additional protocols beyond the default three (UDP, TCP, and ICMP) available in EC2 Classic networking.</p><p>Your choice of networking mode depends on the following considerations:</p><ul><li>Does your cloud need to mimic behavior in your AWS account? If you need EC2-Classic behavior, select EDGE mode. If you need EC2-VPC behavior, select VPCMIDO mode.</li><li>Do you need to create security group rules with additional protocols (e.g., all protocols, RDP, XTP, etc.)? If so, choose VPCMIDO mode.</li><li>If there is no specific requirement for either mode, then VPCMIDO mode is recommended given its flexibility and networking features.</li></ul><p>Each networking mode is described in the following sections.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9e803e1e2ff2aef49d537ffcdab263e0>4.1.6.1 - About Eucanetd</h1><p>The eucanetd service implements artifacts to manage and define Eucalyptus cloud networking. Eucanetd runs alongside the CLC or NC services, depending on the configured networking mode. Eucanetd manages network functionality. For example:</p><ul><li>Installs network artifacts (iptables, ipsets, ebtables, dhcpd)</li><li>Performs state management for the installed network artifacts</li><li>Updates network artifact configuration as needed</li><li>In VPCMIDO mode:<ul><li>Interacts with MidoNet via the MidoNet API</li><li>Defines network artifacts in MidoNet</li></ul></li></ul><h2 id=where-to-deploy-eucanetd>Where to deploy eucanetd</h2><p>Deploy <em>eucanetd</em> depending on the selected network mode:</p><table><thead><tr><th style=text-align:left>Host Machine</th><th style=text-align:left>EDGE mode</th><th style=text-align:left>VPCMIDO mode</th></tr></thead><tbody><tr><td style=text-align:left>CLC</td><td style=text-align:left>No</td><td style=text-align:left>Yes</td></tr><tr><td style=text-align:left>NC</td><td style=text-align:left>Yes</td><td style=text-align:left>No</td></tr></tbody></table><p>When required for a mode <em>eucanetd</em> should be deployed on all hosts for that service.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4a09021661db136481b10bdbcfcadf33>4.1.6.2 - Understanding Eucalyptus EDGE Mode</h1><p>In EDGE networking mode, the components responsible for implementing Eucalyptus VM networking artifacts are running at the edge of a Eucalyptus deployment: the Linux host machines acting as Node Controllers (NCs). On each NC host machine, a Eucalyptus stand-alone service, eucanetd, runs side-by-side with the NC service. The eucanetd service receives dynamically changing Eucalyptus networking views and is responsible for configuring the Linux networking subsystem to reflect the latest view.</p><p>EDGE networking mode integrates with your existing network infrastructure, allowing you to inform Eucalyptus , through configuration parameters for EDGE mode, about the existing network, which Eucalyptus then will consume when implementing the networking view.</p><p>EDGE networking mode integrates with two basic types of pre-existing network setups:</p><ul><li>One flat IP network used to service component systems, VM public IPs (elastic IPs), and VM private IPs.</li><li>Two networks, one for components and VM public IPs, and the other for VM private IPs.</li></ul><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>EDGE networking mode integrates with networks that already exist. If the network, netmask, and router don&rsquo;t already exist, you must create them outside before configuring EDGE mode.</div><h2 id=edge-mode-requirements>EDGE Mode Requirements</h2><ul><li>Each NC host machine must have an interface configured with an IP on a VM public and a VM private network (which can be the same network).</li><li>There must be IP connectivity from each NC host machine (where eucanetd runs) and the CLC host machine, so that network path from instances to the metadata server (running on the CLC host machine) can be established.</li><li>There must be a functioning router in place for the private network. This router will be the default gateway for VM instances.</li><li>The private and public networks can be the same network, but they can also be separate networks.</li><li>The NC host machines need a bridge configured on the private network, with the bridge interface itself having been assigned an IP from the network.</li><li>If you&rsquo;re using a public network, the NC host machines need an interface on the public network as well (if the public and private networks are the same network, then the bridge needs an IP assigned on the network).</li><li>If you run multiple zones, each zone can use the same network as its private network, or they can use separate networks as private networks. If you use separate networks, you need to have a router in place that is configured to route traffic between the networks.</li><li>If you use private addressing only, the CLC host machine must have a route back to the VM private network.</li></ul><h2 id=edge-mode-limitations>EDGE Mode Limitations</h2><ul><li>Global network updates (such as security group rule updates, security group VM membership updates, and elastic IP updates) are applied through an &ldquo;eventually consistent&rdquo; mechanism, as opposed to an &ldquo;atomic&rdquo; mechanism. That is, there may be a brief period of time where one NC has the new state implemented but another NC has the previous state implemented.</li><li>Mappings between VM MAC addresses and private IPs are strictly enforced. This means that instances cannot communicate using addresses the cloud has not assigned to them.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-89eeb5c8d44418651392426591292fef>4.1.6.3 - Understanding VPCMIDO and MidoNet</h1><p>This topic describes MidoNet components and their Eucalyptus deployment options, which provide support for VPC on Eucalyptus. Eucalyptus VPCMIDO mode resembles the Amazon Virtual Private Cloud (VPC) product wherein the network is fully configurable by users. In Eucalyptus, it is implemented with a Software-Defined Networking (SDN) technology called MidoNet. MidoNet is a network virtualization platform for Infrastructure-as-a-Service (IaaS) clouds that implements and exposes virtual network components as software abstractions, enabling programmatic provisioning of virtual networks.</p><p>This network mode requires configuration of MidoNet in order to make cloud networking functional. It offers the most advanced networking capabilities and therefore it is recommended to be used on all new Eucalyptus installations.</p><h2 id=midonet-components>MidoNet Components</h2><p>A MidoNet deployment consists of four types of nodes (according to their logical functions or services offered), connected via four IP networks as depicted in Figure 1. MidoNet does not require any specific hardware, and can be deployed in commodity x86_64 servers. Interactions with MidoNet are accomplished through Application Programming Interface (API) calls, which are translated into (virtual) network topology changes. Network state information is stored in a logically centralized data store, called the Network State Database (NSDB), which is implemented on top of two open-source distributed coordination and data store technologies: ZooKeeper and Cassandra. Implementation of (virtual) network topology is realized via cooperation and coordination among MidoNet agents, which are deployed in nodes that participate in MidoNet.</p><p><img src=https://www.eucastack.io/images/euca_mido_1v2.png alt=image>
<em>Figure 1: Logical view of a MidoNet deployment. Four components are connected via four networks.</em></p><p>Node types:</p><ul><li>MidoNet Network State Database (NSDB): consists of a cluster of ZooKeeper and Cassandra. All MidoNet nodes must have IP connectivity with NSDB.</li><li>MidoNet API: consists of MidoNet web app. Exposes MidoNet REST APIs.</li><li>Hypervisor: MidoNet agent (Midolman) are required in all Hypervisors to enable VMs to be connected via MidoNet overlay networks/SDN.</li><li>Gateway: Gateway nodes are connected to the public network, and enable the network flow from MidoNet overlays to the public network.</li></ul><p>Physical Networks:</p><ul><li>NSDB: IP network that connects all nodes that participate in MidoNet. While NSDB and Tunnel Zone networks can be the same, it is recommended to have an isolated (physical or VLAN) segment.</li><li>API: in deployments only eucanetd/CLC needs access to the API network. Only &ldquo;special hosts/processes&rdquo; should have access to this network. The use of &ldquo;localhost&rdquo; network on the node running CLC/eucanetd is sufficient and recommended in deployments.</li><li>Tunnel Zone: IP network that transports the MidoNet overlay traffic ( VM traffic), which is not &ldquo;visible&rdquo; on the physical network.</li><li>Public network: network with access to the Internet (or corporate/enterprise) network.</li></ul><h2 id=midonet-deployment-scale>MidoNet Deployment Scale</h2><p>Three reference architectures are presented in this document, ordered by complexity and size:</p><ul><li>Proof-of-Concept (PoC)</li><li>Production: Small</li><li>Production: Large</li></ul><p>Production: Large reference architecture represents the most complete and recommended deployment model of MidoNet for Eucalyptus. Whenever possible (such as when resources are available), deployments should closely match with the Production: Large reference architecture (even on small scale clouds).</p><p>All MidoNet components are designed and implemented to horizontally scale. Therefore, it is possible to start small and add resources as they become available.</p><h2 id=eucalyptus-with-midonet>Eucalyptus with MidoNet</h2><p>A Eucalyptus with MidoNet deployment consists of the following components:</p><p><img src=https://www.eucastack.io/images/euca_mido_2.png alt=image>
<em>Figure 2: Logical view of a Eucalyptus with MidoNet deployment. VM private network is created/virtualized by MidoNet, and &lsquo;software-defined&rsquo; by eucanetd. Ideally, each component and network should have its own set of independent resources. In practice, components are grouped and consolidated into a set of servers, as detailed in different reference architectures.</em></p><p>MidoNet components, Eucalyptus components, and three extra networks are present.</p><h2 id=proof-of-concept-poc>Proof of Concept (PoC)</h2><p>The PoC reference architecture is designed for very small and transient workloads, typical in development and testing environments. Quick deployment with minimal external network requirements are the key points of PoC reference architecture.</p><p><strong>Requirements</strong></p><p>Servers:</p><ul><li>Four (4) or more modern Intel cores or AMD modules - exclude logical cores that share CPU resources from the count (Hyperthreads and AMD cores within a module)</li><li>2GB of RAM reserved for MidoNet Agent (when applicable)</li><li>4GB of RAM reserved for MidoNet NSDB (when applicable)</li><li>4GB of RAM reserved for MidoNet API (when applicable)</li><li>30GB of free disk space for NSDB (when applicable)</li></ul><p>Physical Network:</p><ul><li>One (1) 1Gbps IP Network</li><li>A range or list of public IP addresses (Euca_public_IPs)</li><li>Internet Gateway</li></ul><p>Limits:</p><ul><li>Ten (10) MidoNet agents (i.e., 1 Gateway node, 1 CLC, and 8 NCs)</li><li>One (1) MidoNet Gateway</li><li>No fail over, fault tolerance, and/or network load balancing/sharing</li></ul><p><strong>Deployment Topology</strong></p><ul><li>Single server with all MidoNet components (NSDB, API, and Midolman), and with CLC/eucanetd</li><li>A server acting as MidoNet Gateway - when BGP terminated links are used, this node must not be co-located with CLC/eucanetd (in a proxy_arp setup described below, it is possible to consolidate CLC/eucanetd with MidoNet Gateway). This is due to incompatibilities in CentOS/RHEL7 netns (used by eucanetd), and bgpd (started by Midolman when BGP links are configured).</li><li>Hypervisors with Midolman</li><li>One IP network handling NSDB, Tunnel Zone, and Public Network traffic</li><li>API communication via loopback/localhost network</li></ul><p><img src=https://www.eucastack.io/images/euca_mido_3v2.png alt=image>
<em>Figure 3: PoC deployment topology. A single IP network carries NSDB, Tunnel Zone, and Public Network traffic. A single server handles MidoNet NSDB, API (and possibly Gateway) functionality.</em></p><p><strong>MidoNet Gateway Bindings</strong></p><p>Three ways to realize MidoNet Gateway bindings are discussed below, starting with the most recommended setup.</p><p>Public CIDR block(s) allocated for Eucalyptus (Euca_Public_IPs) needs to be routed to MidoNet Gateway by the customer network - this is an environment requirement, outside of control of both MidoNet and Eucalyptus systems. One way to accomplish this is to have a BGP terminated link available. MidoNet Gateway will establish a BGP session with the customer router to: (1) advertise Euca_Public_IPs to the customer router; and (2) get the default route from the customer router.</p><p>If a BGP terminated link is not available, but the routing of Euca_Public_IPs is delegated to MidoNet Gateway (configuration of customer routing infrastructure), similar setup can be used. In such scenario, static routes are configured on the customer router (to route Euca_Public_IPs to MidoNet Gateway), and on MidoNet (to use the customer router as the default route).</p><p><img src=https://www.eucastack.io/images/euca_mido_4.png alt=image>
<em>Figure 4: How servers are bound to MidoNet in a PoC deployment with BGP. A BGP terminated link is required: the gateway node eth device is bound to MidoNet virtual router (when BGP is involved, the MidoNet Gateway and Eucalyptus CLC cannot be co-located). Virtual machine tap devices are bound to MidoNet virtual bridges.</em></p><p>If routed Euca_Public_IPs are not available, static routes on all involved nodes (L2 connectivity is required among nodes) can be used as illustrated below.</p><p><img src=https://www.eucastack.io/images/euca_mido_5.png alt=image>
<em>Figure 5: How servers are bound to MidoNet in a PoC deployment without routed Euca_Public_IPs. Clients that need communication with Euca_Public_IPs configure static routes using MidoNet Gateway as the router. MidoNet Gateway configures a static default route to customer router.</em></p><p>In the case nodes outside the public network broadcast domain (L2) needs to access Euca_Public_IPs, a setup using proxy_arp, as illustrated below, can be used.</p><p><img src=https://www.eucastack.io/images/euca_mido_6.png alt=image>
<em>Figure 6: How servers are bound to MidoNet in a PoC deployment with proxy_arp. When routed Euca_Public_IPs are not available, the gateway node should proxy arp for public IP addresses allocated for Eucalyptus , and forward to a veth device that is bound to a MidoNet virtual router. Virtual machine tap devices are bound to MidoNet virtual bridges.</em></p><h2 id=production-small>Production: Small</h2><p>The Production: Small reference architecture is designed for small scale production quality deployments. It supports MidoNet NSDB fault tolerance (partial failures), and limited MidoNet Gateway failover and load balancing/sharing.</p><p>Border Gateway Protocol (BGP) terminated uplinks are recommended for production quality deployments.</p><p><strong>Requirements</strong></p><p>Servers:</p><ul><li>Four (4) or more modern Intel cores or AMD modules - exclude logical cores that share CPU resources from the count (Hyperthreads and AMD cores within a module) - for gateway nodes, 4 or more cores should be dedicated to MidoNet agent (Midolman)</li><li>4GB of RAM reserved for MidoNet Agent (when applicable), 8GB for Gateway nodes</li><li>4GB of free RAM reserved for MidoNet NSDB (when applicable)</li><li>4GB of free RAM reserved for MidoNet API (when applicable)</li><li>30GB of free disk space for NSDB (when applicable)</li><li>Two (2) 10Gbps NICs per server</li><li>Three (3) servers dedicated to MidoNet NSDB</li><li>Two (2) servers as MidoNet Gateways</li></ul><p>Physical Network:</p><ul><li>One (1) 10Gbps IP Network for public network (if upstream links are 1Gbps, this could be 1Gbps)</li><li>One (1) 10Gbps IP Network for Tunnel Zone and NSDB</li><li>Public Classless Inter-Domain Routing (CIDR) block (Euca_public_IPs)</li><li>Two (2) BGP terminated uplinks</li></ul><p>Limits:</p><ul><li>Thirty two (32) MidoNet agents (i.e., 2 Gateway nodes and 30 Hypervisors)</li><li>Two (2) MidoNet Gateways</li><li>Tolerate 1 NSDB server failure</li><li>Tolerate 1 MidoNet Gateway/uplink failure</li><li>Limited uplinks load sharing/balancing</li></ul><p><strong>Deployment Topology</strong></p><ul><li>A 3-node cluster for NSDB (co-located ZooKeeper and Cassandra)</li><li>eucanetd co-located with MidoNet API Server</li><li>Two (2) MidoNet Gateway Nodes</li><li>Hypervisors with Midolman</li><li>One 10Gbps IP network handling NSDB and Tunnel Zone traffic</li><li>One 10Gbps IP Network handling Public Network traffic</li><li>API communication via loopback/localhost network</li></ul><p><img src=https://www.eucastack.io/images/euca_mido_7v2.png alt=image>
<em>Figure 7: Production:Small deployment topology. A 10Gbps IP network carries NSDB and Tunnel Zone traffic. Another 10Gbps IP network carries Public Network traffic. A 3-node cluster for NSDB tolerates 1 server failure, and 2 gateways enable network failover and limited load balancing/sharing.</em></p><p><img src=https://www.eucastack.io/images/euca_mido_8.png alt=image>
<em>Figure 8: How servers are bound to MidoNet in a Production:Small deployment. Gateway Nodes have physical devices bound to a MidoNet virtual router. These devices should have L2 and L3 connectivity to the Customer&rsquo;s Router, and with BGP terminated links. Virtual machine tap devices are bound to MidoNet virtual bridges.</em></p><p><strong>NSDB Data Replication</strong></p><ul><li>NSDB is deployed in a cluster of 3 nodes</li><li>ZooKeeper and Cassandra both have built-in data replication</li><li>One server failure is tolerated</li></ul><p><strong>MidoNet Gateway Failover</strong></p><ul><li>Two paths are available to and from MidoNet, and failover is handled by BGP</li></ul><p><strong>MidoNet Gateway Load Balancing and Sharing</strong></p><ul><li>Load Balancing from MidoNet is implemented by MidoNet agents (Midolman): ports in a stateful port group with default routes out are used in a round-robin fashion.</li><li>Partial load sharing from the Customer&rsquo;s router to MidoNet can be accomplished by:</li></ul><h2 id=production-large>Production: Large</h2><p>The Production:Large reference architecture is designed for large scale (500 to 600 MidoNet agents) production quality deployments. It supports MidoNet NSDB fault tolerance (partial failures), and MidoNet Gateway failover and load balancing/sharing.</p><p>Border Gateway Protocol (BGP) terminated uplinks are required. Each uplink should come from an independent router.</p><p><strong>Requirements:</strong></p><ul><li>Eight (8) or more modern Intel cores or AMD modules - exclude logical cores that share CPU resources from the count (Hyperthreads and AMD cores within a module) - for gateway nodes, 8 or more cores should be dedicated to MidoNet agent (Midolman)</li><li>4GB of RAM reserved for MidoNet Agent (when applicable), 16GB for Gateway nodes</li><li>4GB of free RAM reserved for MidoNet NSDB (when applicable)</li><li>4GB of free RAM reserved for MidoNet API (when applicable)</li><li>30GB of free disk space for NSDB (when applicable)</li><li>One 1Gbps and 2 10Gbps NICs per server</li><li>Five (5) servers dedicated to MidoNet NSDB</li><li>Three (3) servers as MidoNet Gateways</li></ul><p>Physical Network:</p><ul><li>One 1Gbps IP Network for NSDB</li><li>One 10Gbps IP Network for public network (if upstream links are 1Gbps, this could be 1Gbps)</li><li>One 10Gbps IP Network for Tunnel Zone</li><li>Public Classless Inter-Domain Routing (CIDR) block (Euca_public_IPs)</li><li>Three (3) BGP terminated uplinks, each of which coming from an independent router</li><li>ZooKeeper performance recommendations:</li></ul><p>Limits:</p><ul><li>500 to 600 MidoNet agents</li><li>Three (3) MidoNet Gateways</li><li>Tolerate 1 to 2 NSDB server failures</li><li>Tolerate 1 to 2 MidoNet Gateway/uplink failures</li></ul><p><strong>Deployment Topology</strong></p><ul><li>A 5-node cluster for NSDB (co-located ZooKeeper and Cassandra)</li><li>eucanetd co-located with MidoNet API Server</li><li>Three (3) MidoNet Gateway Nodes</li><li>Hypervisors with Midolman</li><li>One 1Gbps IP network handling NSDB traffic</li><li>One 10Gbps IP network handling Tunnel Zone traffic</li><li>One 10Gbps IP network handling Public Network traffic</li><li>API communication via loopback/localhost network</li></ul><p><img src=https://www.eucastack.io/images/euca_mido_9v2.png alt=image>
<em>Figure 9: Production:Large deployment topology. A 1Gbps IP network carries NSDB; a 10Gbps IP network carries Tunnel Zone traffic; and another 10Gbps IP network carries Public Network traffic. A 5-node cluster for NSDB tolerates 2 server failures, and 3 gateways enable network failover and load balancing/sharing. Servers are bound to MidoNet in a way similar to Production:Small.</em></p><p><strong>NSDB Data Replication</strong></p><ul><li>NSDB is deployed in a cluster of 5 nodes</li><li>ZooKeeper and Cassandra both have built-in data replication</li><li>Up to 2 server failures tolerated</li></ul><p><strong>MidoNet Gateway Failover</strong></p><ul><li>Three paths are available to and from MidoNet, and failover is handled by BGP</li></ul><p><strong>MidoNet Gateway Load Balancing/Sharing</strong></p><ul><li>Load Balancing from MidoNet is implemented by MidoNet agents (Midolman): ports in a stateful port group with default routes out are used in a round-robin fashion.</li><li>The customer AS should handle multi path routing in order to support load sharing/balancing to MidoNet; for example, Equal Cost Multi Path (ECMP).</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-a2181acdf80f6af185740ebc8fad10a0>4.1.7 - Prepare the Network</h1><h1 id=prepare-the-network>Prepare the Network</h1></div><div class=td-content><h1 id=pg-09ac412868e7569242d53b81dd90e21f>4.1.7.1 - Reserve Ports</h1><table><thead><tr><th style=text-align:left>Port</th><th style=text-align:left>Description</th></tr></thead><tbody><tr><td style=text-align:left>TCP 5005</td><td style=text-align:left>DEBUG ONLY: This port is used for debugging (using the &ndash;debug flag).</td></tr><tr><td style=text-align:left>TCP 8772</td><td style=text-align:left>DEBUG ONLY: JMX port. This is disabled by default, and can be enabled with the &ndash;debug or &ndash;jmx options for CLOUD_OPTS.</td></tr><tr><td style=text-align:left>TCP 8773</td><td style=text-align:left>Web services port for the CLC, user-facing services (UFS), object storage gateway (OSG), Walrus SC; also used for external and internal communications by the CLC and Walrus. Configurable with euctl.</td></tr><tr><td style=text-align:left>TCP 8774</td><td style=text-align:left>Web services port on the CC. Configured in the eucalyptus.conf configuration file</td></tr><tr><td style=text-align:left>TCP 8775</td><td style=text-align:left>Web services port on the NC. Configured in the eucalyptus.conf configuration file.</td></tr><tr><td style=text-align:left>TCP 8777</td><td style=text-align:left>Database port on the CLC</td></tr><tr><td style=text-align:left>TCP 8779 (or next available port, up to TCP 8849)</td><td style=text-align:left>jGroups failure detection port on CLC, UFS, OSG, Walrus SC. If port 8779 is available, it will be used, otherwise, the next port in the range will be attempted until an unused port is found.</td></tr><tr><td style=text-align:left>TCP 8888</td><td style=text-align:left>The default port for the Management Console. Configured in the /etc/eucalyptus-console/console.ini file.</td></tr><tr><td style=text-align:left>TCP 16514</td><td style=text-align:left>TLS port on Node Controller, required for instance migrations</td></tr><tr><td style=text-align:left>UDP 7500</td><td style=text-align:left>Port for diagnostic probing on CLC, UFS, OSG, Walrus SC</td></tr><tr><td style=text-align:left>UDP 8773</td><td style=text-align:left>Membership port for any UFS, OSG, Walrus, and SC</td></tr><tr><td style=text-align:left>UDP 8778</td><td style=text-align:left>The bind port used to establish multicast communication</td></tr><tr><td style=text-align:left>TCP/UDP 53</td><td style=text-align:left>DNS port on UFS</td></tr><tr><td style=text-align:left>UDP 63822</td><td style=text-align:left>eucanetd binds to localhost port 63822 and uses it to detect and avoid running multiple instances (of eucanetd)</td></tr></tbody></table><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>For information about ports used by MidoNet, see the (Category OpenStack can be ignored).</div></div><div class=td-content style=page-break-before:always><h1 id=pg-f79af8966d6daed045469c4cbf231034>4.1.7.2 - Verify Connectivity</h1><p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Any firewall running on the CC must be compatible with the dynamic changes performed by when working with security groups. will flush the &lsquo;filter&rsquo; and &rsquo;nat&rsquo; tables upon boot.</div>Verify component connectivity by performing the following checks on the machines that will be running the listed Eucalyptus components.</p><p>Verify connection from an end-user to the CLC on TCP port 8773 Verify connection from an end-user to Walrus on TCP port 8773 Verify connection from the CLC, SC, and NC to SC on TCP port 8773 Verify connection from the CLC, SC, and NC to Walrus on TCP port 8773 Verify connection from Walrus and SC to CLC on TCP port 8777 Verify connection from CLC to CC on TCP port 8774 Verify connection from CC to NC on TCP port 8775 Verify connection from NC to Walrus on TCP port 8773. Or, you can verify the connection from the CC to Walrus on port TCP 8773, and from an NC to the CC on TCP port 8776 Verify connection from public IP addresses of Eucalyptus instances (metadata) and CC to CLC on TCP port 8773 Verify TCP connectivity between CLC, Walrus, and SC on TCP port 8779 (or the first available port in range 8779-8849)  Verify connection between CLC, Walrus, and SC on UDP port 7500 Verify multicast connectivity for IP address 239.193.7.3 between CLC and UFS, OSG, Walrus, and SC on UDP port 8773 If DNS is enabled, verify connection from an end-user and instance IPs to DNS ports If you use tgt (iSCSI open source target) for EBS in DAS or Overlay modes, verify connection from NC to SC on TCP port 3260</p></div><div class=td-content style=page-break-before:always><h1 id=pg-7445d721146b3bd901e55ec91ae81aa4>4.2 - Configure Dependencies</h1><h1 id=configure-dependencies>Configure Dependencies</h1><p>Before you install Eucalyptus , ensure you have the appropriate dependencies installed and configured.</p></div><div class=td-content><h1 id=pg-6cefa559970e018b0616595a7b88f9d3>4.2.1 - Configure Bridges</h1><p>To configure a bridge on CentOS 7 or RHEL 7, you need to create a file with bridge configuration (for example, ifcfg-brX) and modify the file for the physical interface (for example, ifcfg-ethX). The following steps describe how to set up a bridge on both CentOS 7 and RHEL 7. We show examples for configuring bridge devices that either obtain IP addresses using DHCP or statically.</p><p>Install the <code>bridge-utils</code> package.</p><pre><code>yum install bridge-utils
</code></pre><p>Go to the <em>/etc/sysconfig/network-scripts</em> directory:</p><pre><code>cd /etc/sysconfig/network-scripts
</code></pre><p>Open the network script for the device you are adding to the bridge and add your bridge device to it. The edited file should look similar to the following:</p><pre><code>DEVICE=eth0
# change the hardware address to match the hardware address your NIC uses
HWADDR=00:16:76:D6:C9:45
ONBOOT=yes
BRIDGE=br0
NM_CONTROLLED=no
</code></pre><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The device name may vary. See the .</div><p>Create a new network script in the <em>/etc/sysconfig/network-scripts</em> directory called <em>ifcfg-br0</em> or something similar. The br0 is the name of the bridge, but this can be anything as long as the name of the file is the same as the <code>DEVICE</code> parameter, and the name is specified correctly in the previously created physical interface configuration (ifcfg-ethX).<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Choose names and use them consistently for all NCs (both the file name and the in the file).</div>If you are using DHCP, the configuration will look similar to:</p><pre><code>DEVICE=br0
TYPE=Bridge
BOOTPROTO=dhcp
ONBOOT=yes
DELAY=0
</code></pre><p>If you are using a static IP address, the configuration will look similar to:</p><pre><code>DEVICE=br0
TYPE=Bridge
BOOTPROTO=static
IPADDR=static_IP_address
NETMASK=netmask
GATEWAY=gateway
ONBOOT=yes
</code></pre><p>Enter the following command:</p><pre><code>systemctl restart network.service
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-df5626afcae9a08fe87ee2b7a8bdf8ce>4.2.2 - Disable FirewallD on RHEL 7</h1><p>This topic describes how to stop and disable FirewallD on RHEL 7.<strong>Prerequisites</strong></p><ul><li>You should have successfully installed RHEL 7 before this task.
If you have existing firewall rules on your host machines, you must disable the firewall in order to install Eucalyptus . You should re-enable it after installation.<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The firewall on a RHEL 7 system is enabled by default. Before you restart the CLC, you must disable the firewalld service on all host machines.</div></li></ul><p>For more information, see <a href=https://www.certdepot.net/rhel7-get-started-firewalld/>FirewallD on RHEL 7</a> or <a href=https://www.digitalocean.com/community/tutorials/how-to-set-up-a-firewall-using-firewalld-on-centos-7>FirewallD on CentOS</a> .</p><p><strong>To stop and disable FirewallD</strong> Check the status of the firewalld service:</p><pre><code>systemctl status firewalld.service
</code></pre><p>The status displays as <code>active (running)</code> or <code>inactive (dead)</code> . If the firewall is active / running, enter this command to stop it:</p><pre><code>systemctl stop firewalld.service
</code></pre><p>To completely disable the firewalld service, so it does not reload when you restart the host machine:</p><pre><code>systemctl disable firewalld.service
</code></pre><p>Verify the status of the firewalld service:</p><pre><code>systemctl status firewalld.service
</code></pre><p>The status should display as <code>disabled</code> and <code>inactive (dead)</code> .</p><pre><code>firewalld.service - firewalld - dynamic firewall daemon
  Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled)
  Active: inactive (dead)
</code></pre><p>Repeat these steps for all host machines. The firewalld service is stopped and disabled. You can now start the CLC and other host machines.</p><p><strong>Postrequisites</strong></p><ul><li>You should re-enable the firewall after installation is complete.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-1cd6ada50e0e7b78b2d90f4603c34345>4.2.3 - Configure NTP</h1><p>To use NTP:</p><p>Install NTP on the machines that will host Eucalyptus components.</p><pre><code>yum install ntp
</code></pre><p>Open the <em>/etc/ntp.conf</em> file and add NTP servers, if necessary, as in the following example.</p><pre><code>server 0.pool.ntp.org
server 1.pool.ntp.org
server 2.pool.ntp.org
</code></pre><p>Save and close the file. Synchronize your server.</p><pre><code>ntpdate -u YOUR_NTP_SERVER
</code></pre><p>Configure NTP to run at reboot.</p><pre><code>systemctl enable ntpd.service
</code></pre><p>Start NTP.</p><pre><code>systemctl start ntpd.service
</code></pre><p>Synchronize your system clock, so that when your system is rebooted, it does not get out of sync.</p><pre><code>hwclock --systohc
</code></pre><p>Repeat on each host machine that will run a Eucalyptus service.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b492735f6bd0619b5a487201a17fedcc>4.2.4 - Configure Java</h1><p>For the supported version of the Java Virtual Machine (JVM), see the Compatibility Matrix in the Release Notes .</p><p>As of Eucalyptus 4.3, JVM 8 is required. Eucalyptus RPM packages require java-1.8.0-openjdk, which will be installed automatically.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If your network mode is VPCMIDO, MidoNet will install JVM 1.7 as a dependency (it is acceptable to have both JVM 1.7 and JVM 1.8 installed).</div><p><strong>To use Java with Eucalyptus cloud:</strong></p><p>Open the <em>/etc/eucalyptus/eucalyptus.conf</em> file. Verify that the CLOUD_OPTS setting does not set &ndash;java-home , or that &ndash;java-home points to a supported JVM version.<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Although it is possible to set , we do not recommend it unless there is a specific reason to do so.</div>If you are upgrading to Eucalyptus 4.3, note that Java 8 does not have permanent generation memory. Remove any JAVA_OPTS MaxPermSize settings at upgrade time. Save and close the file. Repeat on each host machine that will run a Eucalyptus service.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-eca124ba6897a9d471807816d50dc50d>4.2.5 - Configure an MTA</h1><p>You can use Sendmail, Exim, postfix, or something simpler. The MTA server does not have to be able to receive incoming mail.</p><p>Many Linux distributions satisfy this requirement with their default MTA. For details about configuring your MTA, go to the documentation for your specific product.</p><p>To test your mail relay for localhost, send email to yourself from the terminal using <code>mail</code> .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-d116f8746c016eeb95e02cf25d69dc9b>4.2.6 - Install MidoNet</h1><h1 id=install-midonet>Install MidoNet</h1><p>Eucalyptus requires MidoNet for VPC functionality. This section describes how to install MidoNet for use with Eucalyptus.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are not using VPC with Eucalyptus, you do not need to install MidoNet. See <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configuring_euca/configure_network_modes/nw_edge/>Configure EDGE Network Mode</a>.</div><p><strong>Before you begin:</strong></p><ul><li>See the <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/planning/planning_networking_modes/>Planning your Network</a> section of the guide to create a map of how MidoNet / will be deployed into your environment.</li><li>See the <a href=https://docs.midonet.org/docs/latest-en/quick-start-guide/rhel-7_newton-rdo/content/_midonet_installation.html>MidoNet Installation Guide</a> to become familiar with the general MidoNet installation procedure and concepts.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-5bb925d2c296c64558ffa27487ecb1a6>4.2.6.1 - Prerequisites</h1><p>This topic discusses the prerequisites for installing MidoNet 5.2.</p><p>You need to configure software repositories and install Network State Database (NSDB) services: ZooKeeper and Cassandra.</p><h2 id=repository-access>Repository Access</h2><p>In order to use MidoNet with Eucalyptus you need to configure the MidoNet repositories.</p><p>Create <code>/etc/yum.repos.d/midonet.repo</code> and <code>/etc/yum.repos.d/midonet-misc.repo</code> on all host machines that will run MidoNet components including ZooKeeper and Cassandra. For example:</p><pre><code>[midonet]
name=MidoNet
baseurl=http://builds.midonet.org/midonet-5.2/stable/el7/
enabled=1
gpgcheck=1
gpgkey=https://builds.midonet.org/midorepo.key
</code></pre><p>and:</p><pre><code>[midonet-misc]
name=MidoNet 3rd Party Tools and Libraries
baseurl=http://builds.midonet.org/misc/stable/el7/
enabled=1
gpgcheck=1
gpgkey=https://builds.midonet.org/midorepo.key
</code></pre><p>See <a href=https://docs.midonet.org/docs/latest-en/quick-start-guide/rhel-7_newton-rdo/content/_repository_configuration.html>MidoNet Repository Configuration</a>.</p><h2 id=zookeeper>ZooKeeper</h2><p>MidoNet uses Apache ZooKeeper to store critical path data about the virtual and physical network topology.</p><p>For a simple single-server installation, install ZooKeeper on any server that is IP accessible from all Midolman agents (for example: on the CLC host machine itself). You can also cluster ZooKeeper for fault tolerance. See <a href=https://docs.midonet.org/docs/latest-en/quick-start-guide/rhel-7_newton-rdo/content/_zookeeper_installation.html>MidoNet NSDB ZooKeeper Installation</a>.</p><p>Enable and start the ZooKeeper service before installing the other MidoNet services.</p><h2 id=cassandra>Cassandra</h2><p>MidoNet uses Apache Cassandra to store flow state information.</p><p>For a simple single-server installation, install Cassandra on any server that is IP accessible from all Midolman agents (for example: on the CLC host machine itself). You can also cluster Cassandra for fault tolerance. See <a href=https://docs.midonet.org/docs/latest-en/quick-start-guide/rhel-7_newton-rdo/content/_cassandra_installation.html>MidoNet NSDB Cassandra Installation</a>.</p><p>Enable and start the Cassandra service before installing the other MidoNet services.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5002f76f28ab24c82d06601830a8d53a>4.2.6.2 - MidoNet Component Topology</h1><p>This topic lists topology recommendations for installing MidoNet.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>See [Understanding VPCMIDO and MidoNet]https://www.eucastack.io/docs/install_guide/eucalyptus/planning/planning_networking_modes/preparing_vpc_midonet/ for more information on MidoNet.</div><ul><li>The midonet-api must run co-located with the Cloud Controller (CLC).</li><li>Each Node Controller (NC) must run a Midolman agent.</li><li>The Cloud Controller (CLC) must run a Midolman agent.</li><li>It is recommended that your User Facing Services (UFS) host be used as the MidoNet Gateway (i.e., running a Midolman agent) when configuring .</li><li>The network interface(s) specified as * (in the configuration file) should be dedicated for /MidoNet (for configuration/operation/use).</li><li>/MidoNet expects exclusive use of the network interface specified in .</li><li>If the main network interface of a server is specified in , most likely the connectivity to that server will be lost once is deployed.</li></ul><h2 id=network-yaml-example>Network YAML Example</h2><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The older (JSON) network configuration format is still accepted, however the YAML format is recommended.</div><p>The following Eucalyptus network YAML file shows a sample VPCMIDO mode configuration:</p><pre><code>Mode: VPCMIDO

InstanceDnsServers:
- &quot;10.10.10.1&quot;

PublicIps:
- &quot;1.A.B.1-1.A.B.255&quot;

Mido:
  Gateways:
  - ExternalCidr: &quot;172.19.0.0/30&quot;
    ExternalDevice: &quot;veth1&quot;
    ExternalIp: &quot;172.19.0.2&quot;
    ExternalRouterIp: &quot;172.19.0.1&quot;
    Ip: &quot;10.10.10.1&quot;
</code></pre><p>Where <code>1.A.B.1-1.A.B.255</code> represents the public IP address range for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b670fbdd76e9d8c060bb6a50218a5226>4.2.6.3 - Install MidoNet for Eucalyptus</h1><p>This topic shows how to install MidoNet for use in your Eucalyptus cloud.</p><h2 id=install-the-midonet-cluster-on-the-cloud-controller-clc>Install the MidoNet Cluster on the Cloud Controller (CLC)</h2><p>This topic describes how to install the MidoNet Cluster. MidoNet Cluster services provide a means to manage MidoNet functions that MidoNet agents (Midolman) are unable to perform on their own. MidoNet Cluster services include state synchronization of VxLAN gateways and the MidoNet REST API. A MidoNet v5 deployment requires at least one MidoNet cluster node, and it must be co-located on the CLC host machine in Eucalyptus deployments. For security reasons, the MidoNet REST API is accessed only on the CLC (localhost interface).</p><p><strong>To install the MidoNet Cluster on the CLC</strong></p><p>Add the MidoNet repo file as described in <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/installing_dependencies/install_midonet/install_midonet_prereqs/>Prerequisites</a> . Install MidoNet Cluster packages.</p><pre><code>yum install midonet-cluster python-midonetclient
</code></pre><p>Edit the <em>/etc/midonet/midonet.conf</em> file to set the ZooKeeper host IP(s). Replace ZOOKEEPER_HOST_IP in the following example:</p><pre><code>[zookeeper]
zookeeper_hosts = ZOOKEEPER_HOST_IP:2181 
</code></pre><p>Configure cloud-wide access to the NSDB services:</p><pre><code>cat &lt;&lt; EOF | mn-conf set -t default
zookeeper {
  zookeeper_hosts = “ZOOKEEPER_HOST:2181&quot;
}

cassandra {
  servers = “CASSANDRA_HOST&quot;
}
EOF
</code></pre><p>Enable and start the MidoNet Cluster:</p><pre><code>systemctl enable midonet-cluster.service
systemctl start midonet-cluster.service
</code></pre><p>Set the midonet-api end point:</p><pre><code>mn-conf set cluster.rest_api.http_port=8080
mn-conf set cluster.rest_api.http_host=&quot;127.0.0.1&quot;
</code></pre><p>Restart the Midonet Cluster so the rest_api parameters take effect:</p><pre><code>systemctl restart midonet-cluster.service
</code></pre><h2 id=install-midolman-on-components>Install Midolman on components</h2><p>This topic describes how to install the Midolman agent. Midolman is the MidoNet Agent, which is a daemon that runs on all hosts where traffic enters and leaves MidoNet. The Midolman agent is required on the Cloud Controller (CLC), Node Controllers (NCs), and any host that is a MidoNet Gateway node (e.g., UFS).</p><p><strong>To install Midolman agent</strong></p><p>Edit the <code>/etc/midolman/midolman.conf</code> file to set the ZooKeeper host IP(s). Replace ZOOKEEPER_HOST_IP in the following example:</p><pre><code>[zookeeper]
zookeeper_hosts = ZOOKEEPER_HOST_IP:2181
</code></pre><p>Enable and start Midolman:</p><pre><code>systemctl enable midolman.service
systemctl start midolman.service
</code></pre><p>Configure a Midolman resource usage template. For large Eucalyptus clouds, use the agent-compute-large template. For standard (small or medium) Eucalyptus clouds, use the default template. For gateway nodes, use the agent-gateway templates.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>For production environments, large templates are recommended.</div><p>See the <a href=https://docs.midonet.org/docs/v5.2/en/quick-start-guide/rhel-7_mitaka-rdo/content/_midolman_installation.html>Midolman Installation documentation</a> for more information.</p><p>Choose the Midolman resource usage template name, based on the size and type of installation:</p><pre><code>agent-compute-large
agent-compute-medium
agent-gateway-large
agent-gateway-medium
default
</code></pre><p>Run this command, replacing <code>TEMPLATE_NAME</code> with your chosen template:</p><pre><code>mn-conf template-set -h local -t TEMPLATE_NAME
</code></pre><h2 id=create-a-tunnel-zone-in-midonet-and-add-hosts>Create a tunnel zone in MidoNet and add hosts</h2><p>This topic describes how to create a MidoNet tunnel zone. In MidoNet, a tunnel zone is an isolation zone for hosts. Physical hosts that are members of a given tunnel zone communicate directly with one another and establish network tunnels as needed, and on demand. These network tunnels are used to transport overlay traffic (e.g., inter-VM communication) and isolate the underlay physical network communication (i.e., inter-physical hosts communication). On a Eucalyptus deployment, one MidoNet tunnel zone is expected with the IP address on the physical network designated to carry VM traffic being used when configuring its members. Eucalyptus accepts the following tunnel zone names:</p><ul><li>eucatz</li><li>euca-tz</li><li>midotz</li><li>mido-tz</li></ul><p>For more information, see <a href=https://docs.midonet.org/docs/v5.2/en/operations-guide/content/tunnel_zones.html>What are Tunnel Zones?</a></p><p><strong>To create a tunnel zone in MidoNet</strong></p><p>Log into the MidoNet shell. For example:</p><pre><code>midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api
</code></pre><p>Create a GRE tunnel zone:</p><pre><code>[root@clcfrontend mido-docs]# midonet-cli -A --midonet-url=http://127.0.0.1:8080/midonet-api
midonet&gt; tunnel-zone add name eucatz type gre
midonet&gt; tunnel-zone list
tzone tzone0 name eucatz type gre
midonet&gt; host list
host host0 name node1 alive true
host host1 name clcfrontend alive true
host host2 name node2 alive true
</code></pre><p>You should see a host listed for each of your Node Controllers and for your User Facing Service host; if not, check the <code>/var/log/midolman/midolman.log</code> log file on the missing hosts to ensure there are no error messages.</p><p>After verifying all your hosts are listed, add each host to your tunnel zone as follows. Replace HOST_N_IP with the IP of your Node Controller or User Facing Service host that you used to register the component with Eucalyptus :</p><pre><code>midonet&gt; tunnel-zone tzone0 add member host host0 address HOST_0_IP
midonet&gt; tunnel-zone tzone0 add member host host1 address HOST_1_IP
midonet&gt; tunnel-zone tzone0 add member host host2 address HOST_2_IP
</code></pre><p>You are now ready to install and configure Eucalyptus to use this MidoNet installation.</p><h2 id=additional-zookeeper-configuration>Additional ZooKeeper Configuration</h2><p>Ongoing data directory cleanup is required for ZooKeeper. The following parameters should be added in <em>/etc/zookeeper/zoo.cfg</em> for automatic purging of the snapshots and corresponding transaction logs:</p><pre><code>autopurge.snapRetainCount=3  # The number of snapshots to retain in dataDir
autopurge.purgeInterval=1  # Purge task interval in hours
</code></pre><p>For more information, see <a href=http://zookeeper.apache.org/doc/r3.4.8/zookeeperAdmin.html#Ongoing+Data+Directory+Cleanup>ZooKeeper Admin Guide, Ongoing Data Directory Cleanup</a>.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-671d5e1abc09d2e7bfe7ddbd6dde02d9>4.3 - Install Repositories</h1><h1 id=install-repositories>Install Repositories</h1><p>This section guides you through installing Eucalyptus from RPM package downloads.The first step to installing Eucalyptus is to download the RPM packages. When you&rsquo;re ready, continue to <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/install_repos_intro/installing_euca_software_signing/>Software Signing</a> .</p><p>The following <em>terminology</em> might help you as you proceed through this section.</p><p>Eucalyptus open source software — Eucalyptus release packages and dependencies, which enable you to deploy a Eucalyptus cloud.</p><p>Euca2ools CLI — Euca2ools is the Eucalyptus command line interface for interacting with web services. It is compatible with many Amazon AWS services, so can be used with Eucalyptus as well as AWS.</p><p>RPM and YUM and software signing — Eucalyptus CentOS and RHEL download packages are in RPM (Red Hat Package Manager) format and use the YUM package management tool. We use GPG keys to sign our software packages and package repositories.</p><p>EPEL software — EPEL (Extra Packages for Enterprise Linux) are free, open source software, which is fully separated from licensed RHEL distribution. It requires its own package.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0b4fcc2c7d167b279883e39950e226b6>4.3.1 - Software Signing</h1><p>This topic describes Eucalyptus software signing keys.We use a number of GPG keys to sign our software packages and package repositories. The necessary public keys are provided with the relevant products and can be used to automatically verify software updates. You can also verify the packages or package repositories manually using the keys on this page.</p><p>Use the <code>rpm --checksig</code> command on a download file to verify a RPM package for an Eucalyptus product. For example:</p><pre><code>rpm --checksig -v myfilename.rpm
</code></pre><p>Follow the procedure detailed on Debian&rsquo;s <a href=http://wiki.debian.org/SecureApt#How_to_manually_check_for_package.27s_integrity>SecureApt</a> web page to verify a deb package for an Eucalyptus product.</p><p>Please do not use package signing keys to encrypt email messages.</p><p>The following keys are used for signing Eucalyptus software:</p><h2 id=c1240596-eucalyptus-systems-inc-release-key-securityeucalyptuscom>c1240596: Eucalyptus Systems, Inc. (release key) <a href=mailto:security@eucalyptus.com>security@eucalyptus.com</a></h2><p>This key is used for signing Eucalyptus products released after July 2011 and their updates.</p><ul><li></li><li></li><li>Fingerprint:</li></ul><h2 id=0260cf4e-eucalyptus-systems-inc-pre-release-key-securityeucalyptuscom>0260cf4e: Eucalyptus Systems, Inc. (pre-release key) <a href=mailto:security@eucalyptus.com>security@eucalyptus.com</a></h2><p>This key is used for signing Eucalyptus pre-release products due for release after July 2011.</p><ul><li></li><li></li><li>Fingerprint:</li></ul><h2 id=9d7b073c-eucalyptus-systems-inc-nightly-release-key-securityeucalyptuscom>9d7b073c: Eucalyptus Systems, Inc. (nightly release key) <a href=mailto:security@eucalyptus.com>security@eucalyptus.com</a></h2><p>This key is used for signing nightly builds of Eucalyptus products published after July 2011.</p><ul><li></li><li></li><li>Fingerprint:</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-90008be4c92c3bb568e4cc25e4c50356>4.3.2 - Install Eucalyptus Release Packages</h1><p>To install Eucalyptus from release packages, perform the tasks listed in this topic.</p><p><strong>Prerequisites</strong></p><ul><li>The prerequisite hardware and software should be in place.</li></ul><p><strong>To install Eucalyptus from release packages</strong></p><p>Configure the Eucalyptus package repository on each host machine that will run a Eucalyptus service:</p><pre><code>yum install https://downloads.eucalyptus.cloud/software/eucalyptus/5/rhel/7/x86_64/eucalyptus-release-5-1.11.as.el7.noarch.rpm
</code></pre><p>Enter <code>y</code> when prompted to install this package.</p><p>Configure the Euca2ools package repository on each host machine that will run a Eucalyptus service or Euca2ools:</p><pre><code>yum install https://downloads.eucalyptus.cloud/software/euca2ools/3.4/rhel/7/x86_64/euca2ools-release-3.4-2.2.as.el7.noarch.rpm
</code></pre><p>Enter <code>y</code> when prompted to install this package.</p><p>Configure the EPEL package repository on each host machine that will run a Eucalyptus service or Euca2ools:</p><pre><code>yum install epel-release
</code></pre><p>Enter <code>y</code> when prompted to install this package.</p><p>If you are installing on RHEL 7, you must enable the Optional repository in Red Hat Network for each NC, as follows: Go to <a href=http://rhn.redhat.com>http://rhn.redhat.com</a> and navigate to the system that will run the NC. Click Alter Channel Subscriptions . Make sure the RHEL Server Optional check-box is selected. Click Change Subscriptions .</p><p>On CentOS enable the QEMU Enterprise Virtualization repository for each NC:</p><pre><code>yum install centos-release-qemu-ev
</code></pre><p>The following steps should be performed on each NC host machine. Install the Eucalyptus Node Controller software on each NC host:</p><pre><code>yum install eucalyptus-node
</code></pre><p>Remove the default libvirt network. This step allows the eucanetd dhcpd server to start.</p><pre><code>virsh net-destroy default
virsh net-autostart default --disable
</code></pre><p>Check that the KVM device node has proper permissions. Run the following command:</p><pre><code>ls -l /dev/kvm
</code></pre><p>Verify the output shows that the device node is owned by user root and group kvm.</p><pre><code>crw-rw-rw- 1 root kvm 10, 232 Nov 30 10:27 /dev/kvm
</code></pre><p>If your KVM device node does not have proper permissions, you need to reboot your NC host.</p><p>On each CLC host machine, install the Eucalyptus Cloud Controller software.</p><pre><code>yum install eucalyptus-cloud
</code></pre><p>Install the backend service image package on the machine hosting the CLC:</p><pre><code>yum install eucalyptus-service-image
</code></pre><p>This installs worker images for both the load balancer and imaging services. On the UFS host machine, install the Eucalyptus Cloud Controller software.</p><pre><code>yum install eucalyptus-cloud
</code></pre><p>(Optional) On the UFS host machine, also install the Management Console.</p><pre><code>yum install eucaconsole
</code></pre><p>The Management Console can run on any host machine, even one that does not have other Eucalyptus services . Install the software for the remaining Eucalyptus services. The following example shows services being installed on the same host machine.</p><pre><code>yum install eucalyptus-cluster eucalyptus-sc eucalyptus-walrus
</code></pre><p>This installs the cloud controller (CC), storage controller (SC), and Walrus Backend (Optional) services.</p><p>Your package installation is complete. You are now ready to <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configuring_euca/>Configure Eucalyptus</a> .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-44973e6bf96612bed4bcbdfbd9a7fd95>4.4 - Configure Eucalyptus</h1><p>This section describes the parameters you need to set in order to launch Eucalyptus for the first time.</p><p>The first launch of Eucalyptus is different than a restart of a previously running Eucalyptus deployment in that it sets up the security mechanisms that will be used by the installation to ensure system integrity.</p><p>Eucalyptus configuration is stored in a text file, <em>/etc/eucalyptus/eucalyptus.conf</em>, that contains key-value pairs specifying various configuration parameters.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Perform the following tasks after you install software, but before you start the services.</div></div><div class=td-content style=page-break-before:always><h1 id=pg-14155a79410525e50ff553116b98f68e>4.4.1 - Configure SELinux</h1><p>We recommend enabling SELinux on host systems running Eucalyptus 4.4 services to improve their security on RHEL 7. Enabling SELinux, as described in this topic, can help contain break-ins. For more information, see <a href=https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/html/SELinux_Users_and_Administrators_Guide/chap-Security-Enhanced_Linux-Troubleshooting.html>RedHat SELinux</a> documentation.</p><p>You need to set boolean values on Storage Controller (SC) and Management Console host machines. If your network mode is VPCMIDO, you also set a boolean value on the Cloud Controller (CLC) host machines. <strong>To configure SELinux on Eucalyptus 4.4 :</strong></p><p>On each Storage Controller (SC) host machine, run the following command:</p><pre><code>setsebool -P eucalyptus_storage_controller 1
</code></pre><p>This allows Eucalyptus to manage EBS volumes.</p><p>On each Management Console host machine, run the following command:</p><pre><code>setsebool -P httpd_can_network_connect 1
</code></pre><p>This allows the Management Console&rsquo;s HTTP proxy to access the back end.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you can&rsquo;t access the console after starting it, this KB article might help: .</div><p>If your cloud uses VPCMIDO networking mode, on the Cloud Controller (CLC), run the following command:</p><pre><code>setsebool -P httpd_can_network_connect 1
</code></pre><p>This allows the CLC&rsquo;s HTTP proxy to access the back end.</p><p>SELinux is now configured and ready to use with your Eucalyptus 4.4 cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-b207cc52541e5c29799b86402eba76bf>4.4.2 - Configure Network Modes</h1><p>This section provides configuration instructions for Eucalyptus networking modes. Eucalyptus overlays a virtual network on top of your existing network. In order to do this, Eucalyptus supports these networking modes: EDGE (AWS EC2 Classic compatible) and VPCMIDO (AWS VPC compatible).</p></div><div class=td-content><h1 id=pg-a2a9c18fa398c16422822d97110e4c38>4.4.2.1 - Configure EDGE Network Mode</h1><p>This topic provides configuration instructions for Eucalyptus EDGE network mode. Eucalyptus requires network connectivity between its clients (end-users) and the cloud components (e.g., CC, CLC, and Walrus).</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are not using EDGE mode with Eucalyptus, you can skip this topic. See <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configuring_euca/configure_network_modes/nw_vpmido/>Configure VPCMIDO Network Mode</a>.</div><p>To configure Eucalyptus for EDGE mode, most networking configuration is handled through settings in a global Cloud Controller (CLC) property file.</p><p>The <em>/etc/eucalyptus/eucalyptus.conf</em> file contains some network-related options in the “Networking Configuration” section. These options use the prefix VNET_. The most commonly used VNET options are described in the following table.</p><p>The most commonly used VNET options are described in the following table.</p><table><thead><tr><th style=text-align:left>Option</th><th style=text-align:left>Description</th><th style=text-align:left>Component</th></tr></thead><tbody><tr><td style=text-align:left>VNET_BRIDGE</td><td style=text-align:left>This is the name of the bridge interface to which instances&rsquo; network interfaces should attach. A physical interface that can reach the CC must be attached to this bridge. Common setting for KVM is br0.</td><td style=text-align:left>Node Controller</td></tr><tr><td style=text-align:left>VNET_DHCPDAEMON</td><td style=text-align:left>The ISC DHCP executable to use. This is set to a distro-dependent value by packaging. The internal default is /usr/sbin/dhcpd3.</td><td style=text-align:left>Node Controller</td></tr><tr><td style=text-align:left>VNET_MODE</td><td style=text-align:left>The networking mode in which to run. The same mode must be specified on all CCs and NCs in your cloud. Valid values: EDGE</td><td style=text-align:left>All CCs and NCs</td></tr><tr><td style=text-align:left>VNET_PRIVINTERFACE</td><td style=text-align:left>The name of the network interface that is on the same network as the NCs. Default: eth0</td><td style=text-align:left>Node Controller</td></tr><tr><td style=text-align:left>VNET_PUBINTERFACE</td><td style=text-align:left>This is the name of the network interface that is connected to the same network as the CC. Depending on the hypervisor&rsquo;s configuration this may be a bridge or a physical interface that is attached to the bridge. Default: eth0</td><td style=text-align:left>Node Controller</td></tr></tbody></table><p>You must edit <em>eucalyptus.conf</em> on the Cluster Controller (CC) and Node Controller (NC) hosts. You must also create a network configuration file and upload it the Cloud Controller (CLC).</p><h2 id=cc-configuration>CC Configuration</h2><p>Log in to the CC and open the <em>/etc/eucalyptus/eucalyptus.conf</em> file. Go to the <strong>Network Configuration</strong> section, uncomment and set the following:</p><pre><code>VNET_MODE=&quot;EDGE&quot;
</code></pre><p>Save the file. Repeat on each CC in your cloud.</p><h2 id=nc-configuration>NC Configuration</h2><p>Log into an NC machine and open the <em>/etc/eucalyptus/eucalyptus.conf</em> file. Go to the <strong>Network Configuration</strong> section, uncomment and set the following parameters:</p><pre><code>VNET_MODE
VNET_PRIVINTERFACE
VNET_PUBINTERFACE
VNET_BRIDGE
VNET_DHCPDAEMON
</code></pre><p>For example:</p><pre><code>VNET_MODE=&quot;EDGE&quot;
VNET_PRIVINTERFACE=&quot;br0&quot;
VNET_PUBINTERFACE=&quot;br0&quot;
VNET_BRIDGE=&quot;br0&quot;
VNET_DHCPDAEMON=&quot;/usr/sbin/dhcpd&quot;
</code></pre><p>Save the file. Repeat on each NC.</p><h2 id=cloud-configuration>Cloud Configuration</h2><p>To configure the rest of the EDGE mode parameters, you must create a <em>network.yaml</em> configuration file. Later in the installation process you will <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configure_runtime/nw_json_upload/>Upload the Network Configuration</a> to the CLC.</p><p>Create the network configuration file. Open a text editor. Create a file similar to the following structure.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#8f5902;font-style:italic># A list of servers that instances receive to resolve DNS names</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>InstanceDnsServers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#8f5902;font-style:italic># List of public IP addresses or address ranges</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>PublicIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#8f5902;font-style:italic># A list of cluster objects that define each availability zone (AZ) in your cloud</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>Clusters</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>-<span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#8f5902;font-style:italic># Name of the cluster as it was registered</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#8f5902;font-style:italic># Subnet definition that this cluster will use for private addressing</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#8f5902;font-style:italic># Arbitrary name for the subnet</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#8f5902;font-style:italic># The subnet that will be used for private addressing</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#8f5902;font-style:italic># Netmask for the subnet defined above</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Netmask</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#8f5902;font-style:italic># Gateway that will route packets for the private subnet</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#8f5902;font-style:italic># List of Private IP addresses or address ranges for instances   </span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>PrivateIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>Save the <em>network.json</em> file. The following example is for a setup with one cluster (AZ), called PARTI00, with a flat network topology.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>InstanceDnsServers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.1.1.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>PublicIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.111.101.84&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.111.101.91-10.111.101.93&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>Clusters</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>PARTI00</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Netmask</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;255.255.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.1&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>PrivateIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.94&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.95&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>For a multi-cluster deployment, add an additional cluster to your configuration for each cluster you have. The following example has an two clusters, <strong>PARTI00</strong> and <strong>PARTI01</strong>.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>InstanceDnsServers</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.1.1.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>PublicIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.111.101.84&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.111.101.91-10.111.101.93&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>Clusters</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>PARTI00</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Netmask</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;255.255.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.1&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>PrivateIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.94&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.95&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>PARTI01</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Name</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Subnet</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Netmask</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;255.255.0.0&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>Gateway</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.0.1&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>PrivateIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.96&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#4e9a06>&#34;10.111.101.97&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-8a92c056ba1bcd9ef177398b6531e644>4.4.2.2 - Configure VPCMIDO Network Mode</h1><p>This topic provides configuration instructions for Eucalyptus VPCMIDO network mode. Eucalyptus requires network connectivity between its clients (end-users) and the cloud components (e.g., CC, CLC, and storage).</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are not using VPCMIDO mode with Eucalyptus, you can skip this topic. See <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configuring_euca/configure_network_modes/nw_edge/>Configure EDGE Network Mode</a>.</div><p>To configure VPCMIDO mode parameters, you must create a <em>network.yaml</em> configuration file. Later in the installation process you will <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configure_runtime/nw_json_upload/>Upload the Network Configuration</a> to the CLC.</p><p>Create the network configuration file. Open a text editor. Create a file similar to the following structure. This example demonstrates two gateways and two BGP peers (sections relevant to VPCMIDO are shown here).</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>Mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>VPCMIDO</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>PublicIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.116.150.10-10.116.150.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.117.150.10-10.117.150.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>Mido</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>BgpAsn</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;64512&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Gateways</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#204a87;font-weight:700>Ip</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.5.11&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalDevice</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;em1.116&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalCidr</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.128.0/17&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.133.11&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpPeerIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.133.173&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpPeerAsn</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;65000&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpAdRoutes</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span>- <span style=color:#4e9a06>&#34;10.116.150.0/24&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#204a87;font-weight:700>Ip</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.5.22&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalDevice</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;em1.117&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalCidr</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.117.128.0/17&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.117.133.22&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpPeerIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.117.133.173&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpPeerAsn</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;65001&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>BgpAdRoutes</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span>- <span style=color:#4e9a06>&#34;10.117.150.0/24&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div><p>Save the <em>network.yaml</em> file. The following example demonstrates a gateway with static routing configuration.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#204a87;font-weight:700>Mode</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>VPCMIDO</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>PublicIps</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span>- <span style=color:#4e9a06>&#34;10.116.150.10-10.116.150.254&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#204a87;font-weight:700>Mido</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>Gateways</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>  </span>- <span style=color:#204a87;font-weight:700>Ip</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.111.5.11&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalDevice</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;em1.116&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalCidr</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.128.0/17&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.133.11&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span><span style=display:flex><span><span style=color:#f8f8f8;text-decoration:underline>    </span><span style=color:#204a87;font-weight:700>ExternalRouterIp</span><span style=color:#000;font-weight:700>:</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#34;10.116.133.173&#34;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-f8ba73af96d5cbb99b41ddffed1ee80e>4.4.2.2.1 - VPCMIDO Gateway Configuration Parameters</h1><p>This topic provides detailed configuration parameter information for Eucalyptus VPCMIDO network mode.</p><h2 id=vpcmido-gateway-configuration>VPCMIDO Gateway Configuration</h2><p>The following table provides a list of VPCMIDO parameters.</p><table><thead><tr><th style=text-align:left>Parameter</th><th style=text-align:left>Description</th><th style=text-align:left>Validation</th></tr></thead><tbody><tr><td style=text-align:left>BgpAsn</td><td style=text-align:left>(Optional) Global BGP configuration *BGP Autonomous System Number assigned (to be decided by administrator/installer) for this VPCMIDO deployment. Private ASN range should be used:16-bit: 64512 - 6553432-bit: 131072 - 4199999999 (RFC6996)</td><td style=text-align:left>Private use blocks recommended, but owners of public ASNs can use public ASNs or other blocks if they wish.Valid range is 1 - 4294967295.</td></tr><tr><td style=text-align:left>Gateways</td><td style=text-align:left>(The VPCMIDO gateway parameters are below.)</td><td style=text-align:left>Per MidoNet/BGP limitation, a maximum of 6 MidoGateways can be used.</td></tr><tr><td style=text-align:left>Ip</td><td style=text-align:left>Internal IP address of Mido Gateway (not to be confused with the IP address of the gateway interface used in external communications). Note: Replaces 4.3 GatewayHost parameter.</td><td style=text-align:left>Must be a valid IP address.Must be a live IP address configured on the machine.</td></tr><tr><td style=text-align:left>ExternalDevice</td><td style=text-align:left>Device name of Mido Gateway interface that is physically connected to the external network (i.e., has L2 connectivity to the infrastructure router or BGP peer). This interface is dedicated for MidoNet use (Mido Gateway Operating System should not have control of this device). Note: Replaces 4.3 GatewayInterface parameter.</td><td style=text-align:left>Must be a valid network interface connected to the network where L2 communication with BgpPeerIp (or ExternalRouterIp) can be established.</td></tr><tr><td style=text-align:left>ExternalCidr</td><td style=text-align:left>CIDR block used in the external routing. Note: Replaces 4.3 PublicNetworkCidr parameter.</td><td style=text-align:left>Must be a valid CIDR block.</td></tr><tr><td style=text-align:left>ExternalIp</td><td style=text-align:left>IP address to be configured on ExternalDevice by eucanetd. Its subnet is as specified in ExternalCidr (ExternalCidr must contain ExternalIp). Note: Replaces 4.3 GatewayIP parameter.</td><td style=text-align:left>Must be a valid and unused IP address.Must be within ExternalCidr.Must not be a network or broadcast address.</td></tr><tr><td style=text-align:left>ExternalRouterIp</td><td style=text-align:left>IP address of an external router (for static configuration). This is the router IP address used in default routes for traffic originating from MidoNet. Note: Partially replaces 4.3 PublicGatewayIp parameter.</td><td style=text-align:left>Must be a valid and unused IP address.Must be within ExternalCidr.Must not be a network or broadcast address.Either ExternalRouterIp or BgpPeerIp is required.</td></tr><tr><td style=text-align:left>BgpPeerIp</td><td style=text-align:left>(Optional) BGP configuration * IP address of a BGP peer. This is the IP address to where MidoNet router will attempt to establish a BGP session.Note: Partially replaces 4.3 PublicGatewayIp parameter.</td><td style=text-align:left>Must be a valid and unused IP address.Must be within ExternalCidr.Must not be a network or broadcast address.Either ExternalRouterIp or BgpPeerIp is required.</td></tr><tr><td style=text-align:left>BgpPeerAsn</td><td style=text-align:left>(Optional) BGP configuration * BGP peer ASN for this MidoGateway.</td><td style=text-align:left>Valid range is 1 - 4294967295.</td></tr><tr><td style=text-align:left>BgpAdRoutes</td><td style=text-align:left>(Optional) BGP configuration * A list of CIDR blocks delegated to this VPCMIDO deployment. VPCMIDO BGP will be configured to advertise these routes. public IPs must be within these CIDR blocks. The same list can be used for all MidoGateways. The advantage of having a separate list per MidoGateway is that it allows different MidoGateways to be responsible for different CIDR blocks. If the same list of CIDR blocks is used for all MidoGateways, MidoNet built-in load sharing/balancing mechanism is used.</td><td style=text-align:left>Each entry must be a valid CIDR block.</td></tr><tr><td style=text-align:left>PublicIps</td><td style=text-align:left>The public IP address ranges associated with VPCMIDO.</td><td style=text-align:left>With BGP: Each public IP must be within one of the CIDR blocks in the union of all BgpAdRoutes entries.Must be a valid IP address range.Must not contain network or broadcast address of the CIDR blocks in the union of all BgpAdRoutes.Without BGP: On-premise infrastructure must route all PublicIps to one of the MidoGateways.</td></tr></tbody></table><p>Gateways with BGP require <em>BgpPeerAsn</em> , <em>BgpAdRoutes</em> , and <em>BgpAsn</em> . If all gateways are static (no BGP), <em>BgpAsn</em> is optional. A gateway with BGP has <em>BgpPeerAsn</em> and <em>BgpAdRoutes</em> parameters; a static gateway does not.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-4a69989b840665db85b061db956b4cb4>4.4.3 - Create Scheduling Policy</h1><p>This topic describes how to set up the Cluster Controller (CC) to choose which Node Controller (NC) to run each new instance.In the CC, open the <em>/etc/eucalyptus/eucalyptus.conf</em> file. In the <code>SCHEDPOLICY=</code> parameter, set the value to one of the following: <code>GREEDY</code> When the CC receives a new instance run request, it runs the instance on the first NC in an ordered list of NCs that has capacity to run the instance. At partial capacity with some amount of churn, this policy generally results in a steady state over time where some nodes are running many instances, and some nodes are running few or no instances. <code>ROUNDROBIN</code> (Default) When the CC receives a new instance run request, it runs the instance on the next NC in an ordered list of NCs that has capacity. The next NC is determined by the last NC to have received an instance. At partial capacity with some amount of churn, this policy generally results in a steady state over time where instances are more evenly distributed across the set of NCs. Save the file.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-5ae0c9c8d53a01fedd24bb294ad33591>4.5 - Start Eucalyptus</h1><h1 id=start>Start</h1><p>Start the Eucalyptus services in the order presented in this section. Make sure that each host machine you installed a Eucalyptus service on resolves to an IP address. Edit the <em>/etc/hosts</em> file if necessary.</p></div><div class=td-content><h1 id=pg-e5e8324b00fdfa50dcd59ddbf6f60ddb>4.5.1 - Start the CLC</h1><p><strong>Prerequisites</strong> You should have installed and configured Eucalyptus before starting the CLC.</p><p><strong>To initialize and start the CLC</strong></p><p>Log in to the Cloud Controller (CLC) host machine. Enter the following command to initialize the CLC:<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are upgrading and you just restored your cloud data, do not initialize the CLC; skip this step.</div></p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Make sure that the process is running before executing this command.</div><pre><code>clcadmin-initialize-cloud
</code></pre><p>This command might take a minute or more to finish. If it fails, check <em>/var/log/eucalyptus/cloud-output.log</em> . If you want the CLC service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-cloud.service
</code></pre><p>Enter the following command to start the CLC:</p><pre><code>systemctl start eucalyptus-cloud.service
</code></pre><p>If you are running in VPCMIDO networking mode: If you want the eucanetd service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucanetd.service
</code></pre><p>Start the eucanetd service:</p><pre><code>systemctl start eucanetd.service
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-e52984760577000fde6160fd154cc81e>4.5.2 - Start the UFS</h1><p><strong>Prerequisites</strong> You should have installed and configured Eucalyptus before starting the UFS.</p><p><strong>To start the UFS</strong></p><p>Log in to the User-Facing Services (UFS) host machine. If you want the UFS service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-cloud.service
</code></pre><p>Enter the following command to start the UFS:</p><pre><code>systemctl start eucalyptus-cloud.service
</code></pre><p>Repeat for each UFS host machine.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-914aa1501b6ef1bcbb0e19230cf43590>4.5.3 - Start Walrus</h1><p><strong>Prerequisites</strong></p><p>You should have installed and configured Eucalyptus before starting the Walrus Backend.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you not using Walrus as your object storage backend, or if you installed Walrus on the same host as the CLC, you can skip this.</div><p><strong>To start the Walrus</strong></p><p>If you want the Walrus Backend service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-cloud.service
</code></pre><p>Log in to the Walrus Backend host machine and enter the following command:</p><pre><code>systemctl start eucalyptus-cloud.service
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-fba34cb1eb8eead504cd60172f4a0f09>4.5.4 - Start the CC</h1><p><strong>Prerequisites</strong></p><p>You should have installed and configured Eucalyptus before starting the CC.</p><p><strong>To start the CC</strong></p><p>Log in to the Cluster Controller (CC) host machine. If you want the CC service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-cluster.service
</code></pre><p>Enter the following command to start the CC:</p><pre><code>systemctl start eucalyptus-cluster.service
</code></pre><p>If you have a multi-zone setup, repeat this step on the CC in each zone.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-f56ccb1e4b8ad50651edc72cca7ba09d>4.5.5 - Start the SC</h1><p><strong>Prerequisites</strong></p><p>You should have installed and configured Eucalyptus before starting the SC.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are re-installing the SC, restart the tgt (iSCSI open source target) daemon.</div><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you installed SC on the same host as the CLC, you can skip this.</div><p><strong>To start the SC</strong></p><p>Log in to the Storage Controller (SC) host machine. If you want the SC service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-cloud.service
</code></pre><p>If you want the tgtd service to start at each boot-time, run this command:</p><pre><code>systemctl enable tgtd.service
</code></pre><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>depends on tgtd to create and manage block storage volumes when the storage provider is either DAS or Overlay.</div><p>Enter the following commands to start the SC:</p><pre><code>systemctl start tgtd.service

systemctl start eucalyptus-cloud.service
</code></pre><p>If you have a multi-zone setup, repeat this step on the SC in each zone.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a2992fd0511e4cd5b3e30621ca66c715>4.5.6 - Start the NC</h1><p><strong>Prerequisites</strong> You should have installed and configured Eucalyptus before starting the NC.</p><p><strong>To start the NC</strong></p><p>Log in to the Node Controller (NC) host machine. If you want the NC service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucalyptus-node.service
</code></pre><p>Enter the following command to start the NC:</p><pre><code>systemctl start eucalyptus-node.service
</code></pre><p>If you are running in EDGE networking mode: If you want the eucanetd service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucanetd.service
</code></pre><p>Start the eucanetd service:</p><pre><code>systemctl start eucanetd.service
</code></pre><p>Repeat for each NC host machine.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-42ad0538f40eb9fe89a3ea0967ab4d80>4.5.7 - Start the Management Console</h1><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you plan on running multiple Management Console host machines, we recommend turning off the default memcached in your console.ini file.</div><p>Log in to the Management Console host machine. If you want the console service to start at each boot-time, run this command:</p><pre><code>systemctl enable eucaconsole.service
</code></pre><p>Enter the following command to start the console:</p><pre><code>systemctl start eucaconsole.service
</code></pre><p>Repeat for each Management Console host machine.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-e7dfbf0222ff21863a7a57492266c6d4>4.5.8 - Verify the Startup</h1><p>At this point, all Eucalyptus services are enabled and starting up. Some of these services perform intensive initialization at start-up, particularly the first time they are started. You might have to wait a few minutes until they are fully operational.</p><p>One quick way to determine if the components are running is to run netstat on the various hosts and look to see when the service ports are allocated to a process. Specifically, the CLC, Walrus, and the SC allocate ports 8773. The CC listens to port 8774, and the NC uses port 8775.</p><p>Verify that everything has started without error. Expected outcomes include:</p><ul><li>The CLC is listening on port 8773</li><li>Walrus is listening on port 8773</li><li>The SC is listening on port 8773</li><li>The CC is listening on port 8774</li><li>The NCs are listening on port 8775</li><li>Log files are being written to</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-108e0ca8c7851c5668e3b09f56eae60e>4.6 - Register Eucalyptus Services</h1><h1 id=register-services>Register Services</h1><p>This section describes how to register Eucalyptus services.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you are upgrading, proceed to the section. (You don&rsquo;t need to register the rest (e.g., UFS, Walrus, etc.) during the non-NC upgrade, because those registrations are already listed in the cloud database, which you recovered before getting here.)</div><p>Eucalyptus implements a secure protocol for registering separate services so that the overall system cannot be tricked into including a service run by an unauthorized administrator or user.</p><p>You need only register services once. Most registration commands run on the CLC server.</p><p>Note that each registration command will attempt an SSH as root to the remote physical host where the registering service is assumed to be running. The registration command also contacts the service so it must be running at the time the command is issued. If a password is required to allow SSH access, the command will prompt the user for it.</p><p>Registration commands need the following information:</p><ul><li>The of service you are registering. Required. For example: .</li><li>The of the service being registered. Required. The host must be specified by IP address to function correctly.</li><li>The the service belongs to. This is roughly equivalent to the availability zone in AWS.</li><li>The you assign to each instance of a service, up to 256 characters. Required. This is the name used to identify the service in a human-friendly way. This name is also used when reporting system state changes that require administrator attention.</li></ul></div><div class=td-content style=page-break-before:always><h1 id=pg-6c3b799939e318d49db2499a7bd58541>4.6.1 - Register User-Facing Services</h1><p>This topic describes how to register the User-Facing Services (UFS) with the Cloud Controller (CLC).</p><p><strong>Prerequisites</strong></p><ul><li>The Cloud Controller must be properly installed and started.</li><li>The User-Facing Services must be properly installed and started.</li></ul><p><strong>To register the User-Facing Services with the Eucalyptus cloud</strong></p><p>On the CLC host machine, obtain your temporary access keys for the Eucalyptus set up by running the following command:</p><pre><code>eval `clcadmin-assume-system-credentials`
</code></pre><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>You will create longer-lived and fully functional access keys later.</div><p>Also on the CLC host machine, run the following command:</p><pre><code>euserv-register-service -t user-api -h IP SVCINSTANCE
</code></pre><p>where:</p><ul><li><code>SVCINSTANCE</code> is the IP address of the UFS you are registering.</li><li>must be a unique name for the User-Facing service.</li></ul><p>For example:</p><pre><code>euserv-register-service -t user-api -h 10.111.5.183 user-api-1
</code></pre><p>Repeat for each UFS host, replacing the UFS IP address and UFS name. Copy the security credentials from the CLC to each machine running User-Facing Services. Run this command on the CLC host machine:</p><pre><code>clcadmin-copy-keys HOST [HOST ...]
</code></pre><p>For example:</p><pre><code>clcadmin-copy-keys 10.111.5.183
</code></pre><p>Verify that the User-Facing service is registered with the following command for each instance of the UFS:</p><pre><code>euserv-describe-services SVCINSTANCE
</code></pre><p>The registered UFS instances are now ready for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-0333fa64f2ebc68bd3e0ed029d46c621>4.6.2 - Register the Walrus Backend</h1><p>This topic describes how to register the Walrus Backend service with the Cloud Controller (CLC).</p><p><strong>Prerequisites</strong></p><ul><li>You must be using the Walrus Backend service as your object storage provider.</li><li>The Cloud Controller must be properly installed and started.</li></ul><p><strong>To register the Walrus Backend service with the Eucalyptus cloud</strong></p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>This task is not necessary if you are using Riak CS instead of Walrus.</div><p>On the CLC host machine, run the following command:</p><pre><code>euserv-register-service -t walrusbackend -h IP SVCINSTANCE
</code></pre><p>where:</p><ul><li><code>SVCINSTANCE</code> is the IP of the Walrus Backend you are registering with this CLC.</li><li>must be a unique name for the Walrus Backend service. We recommend that you use a short-hand name of the hostname or IP address of the machine.</li></ul><p>For example:</p><pre><code>euserv-register-service -t walrusbackend -h 10.111.5.182 walrus-10.111.5.182
</code></pre><p>Copy the security credentials from the CLC to each machine running a Walrus Backend service. Run this command on the CLC host machine:</p><pre><code>clcadmin-copy-keys HOST [HOST ...]
</code></pre><p>For example:</p><pre><code>clcadmin-copy-keys 10.111.5.182
</code></pre><p>Verify that the Walrus Backend service is registered with the following command:</p><pre><code>euserv-describe-services SVCINSTANCE
</code></pre><p>The registered Walrus Backend service is now ready for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-04341adcb357c8048563067bfaf9e9fd>4.6.3 - Register the Cluster Controller</h1><p>This topic describes how to register a Cluster Controller (CC) with the Cloud Controller (CLC).</p><p><strong>Prerequisites</strong></p><ul><li>The Cloud Controller must be properly installed and started.</li><li>The Cluster Controller service must be properly installed and started.</li></ul><p><strong>To register the Cluster Controller service with the Eucalyptus cloud</strong></p><p>On the CLC host machine, run the following command:</p><pre><code>euserv-register-service -t cluster -h IP -z ZONE SVCINSTANCE
</code></pre><p>where:</p><ul><li><code>SVCINSTANCE</code> is the IP address of the CC you are registering with this CLC.</li><li>name should be a descriptive name for the zone controlled by the CC. For example: .</li><li>must be a unique name for the CC service. We recommend that you use the IP address of the machine</li></ul><p>For example:</p><pre><code>euserv-register-service -t cluster -h 10.111.5.182 -z zone-1 cc-10.111.5.182
</code></pre><p>Copy the security credentials from the CLC to each machine running Cluster Controller services. Run this command on the CLC host machine:</p><pre><code>clcadmin-copy-keys -z ZONE HOST
</code></pre><p>For example:</p><pre><code>clcadmin-copy-keys -z zone-1 10.111.5.182
</code></pre><p>Repeat the above steps for each Cluster Controller in each zone. Verify that the Cluster Controller service is registered with the following command:</p><pre><code>euserv-describe-services SVCINSTANCE
</code></pre><p>The registered Cluster Controller service is now ready for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a4d7a5b8052a5795166ed717511322d1>4.6.4 - Register the Storage Controller</h1><p>This topic describes how to register a Storage Controller (SC) with the Cloud Controller (CLC).</p><p><strong>Prerequisites</strong></p><ul><li>The Cloud Controller must be properly installed and started.</li><li>The Storage Controller service must be properly installed and started.</li></ul><p><strong>To register the Storage Controller service with the Eucalyptus cloud</strong></p><p>Copy the security credentials from the CLC to each machine running Storage Controller services. Run this command on the CLC host machine:</p><pre><code>clcadmin-copy-keys -z ZONE HOST
</code></pre><p>For example:</p><pre><code>clcadmin-copy-keys -z zone-1 10.111.5.182
</code></pre><p>On the CLC host machine, run the following command:</p><pre><code>euserv-register-service -t storage -h IP -z ZONE SVCINSTANCE
</code></pre><p>where:</p><ul><li><code>SVCINSTANCE</code> is the IP address of the SC you are registering with this CLC.</li><li>name should be a descriptive name for the zone controlled by the CC. For example: . An SC must have the same name as the CC in the same zone.</li><li>must be a unique name for the SC service. We recommend that you use a short-hand name of the IP address or hostname of the machine.</li></ul><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>We recommend that you use IP addresses instead of DNS names when registering services.</div><p>For example:</p><pre><code>euserv-register-service -t storage -h 10.111.5.182 -z zone-1 sc-10.111.5.182
</code></pre><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The SC automatically goes to the state after being registered with the CLC; it will remain in that state until you explicitly configure the SC by configuring the backend storage provider (later). For more information, see .</div><p>Repeat the above steps for each Storage Controller in each zone. Verify that the Storage Controller service is registered with the following command:</p><pre><code>euserv-describe-services SVCINSTANCE
</code></pre><p>The registered Storage Controller service is now ready for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-df7fcaa99d87b06e61625e4a49b721de>4.6.5 - Register the Node Controllers</h1><p>This topic describes how to register a Node Controller (NC) with a Cluster Controller (CC).</p><p><strong>Prerequisites</strong></p><ul><li>The Cluster Controller service must be properly installed and started.</li><li>The Node Controller service must be properly installed and started.</li><li>If you are upgrading, you should understand that:<ul><li>If you&rsquo;re upgrading an NC, just register that NC (on the CC that had it registered before).</li><li>If you&rsquo;re upgrading the set of non-NC host machines, register all the NCs (on each CC that had NCs registered).</li></ul></li></ul><p><strong>To register the Node Controller service with the Eucalyptus cloud</strong></p><p>SSH to the Cluster Controller in the zone. On the CC, register all NCs using the following command with the IP address of each NC host machine:</p><pre><code>clusteradmin-register-nodes node0_IP_address ... [nodeN_IP_address]
</code></pre><p>For example:</p><pre><code>clusteradmin-register-nodes 10.111.5.160 10.111.5.161 10.111.5.162
</code></pre><p>Copy the CC&rsquo;s security credentials using the following command:</p><pre><code>clusteradmin-copy-keys node0_IP_address ... [nodeN_IP_address]
</code></pre><p>For example:</p><pre><code>clusteradmin-copy-keys 10.111.5.160 10.111.5.161 10.111.5.162
</code></pre><p>Repeat the steps for each zone in your cloud. The registered Node Controller service is now ready for your cloud.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-9f6ef2abc861228ad98d0746a52e3bbf>4.7 - Configure the Runtime Environment</h1><h1 id=configure-the-runtime-environment>Configure the Runtime Environment</h1><p>After Eucalyptus is installed and registered, perform the tasks in this section to configure the runtime environment.Now that you have installed Eucalyptus , you&rsquo;re ready to begin configuring and using it.</p></div><div class=td-content><h1 id=pg-a0ef37a70072d465efc415fbe578fa67>4.7.1 - Configure Eucalyptus DNS</h1><p>Eucalyptus provides a DNS service that maps service names, bucket names, and more to IP addresses. This section details how to configure the Eucalyptus DNS service.<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>administration tools are designed to work with DNS-enabled clouds, so configuring this service is highly recommended. The remainder of this guide is written with the assumption that your cloud is DNS-enabled.</div>The DNS service will automatically try to bind to port 53. If port 53 cannot be used, DNS will be disabled. Typically, other system services like dnsmasq are configured to run on port 53. To use the Eucalyptus DNS service, you must disable these services.</p><h2 id=configure-the-domain-and-subdomain>Configure the Domain and Subdomain</h2><p>Before using the DNS service, configure the DNS subdomain name that you want Eucalyptus to handle using the steps that follow.</p><p>Log in to the CLC and enter the following:</p><pre><code>euctl system.dns.dnsdomain=mycloud.example.com
</code></pre><p>You can configure the load balancer DNS subdomain. To do so, log in to the CLC and enter the following:</p><pre><code>euctl services.loadbalancing.dns_subdomain=lb
</code></pre><h2 id=turn-on-ip-mapping>Turn on IP Mapping</h2><p>To enable mapping of instance IPs to DNS host names:</p><p>Enter the following command on the CLC:</p><pre><code>euctl bootstrap.webservices.use_instance_dns=true
</code></pre><p>When this option is enabled, public and private DNS entries are created for each launched instance in Eucalyptus . This also enables virtual hosting for Walrus. Buckets created in Walrus can be accessed as hosts. For example, the bucket <code>mybucket</code> is accessible as <code>mybucket.objectstorage.mycloud.example.com</code> .</p><p>Instance IP addresses will be mapped as <code>euca-A-B-C-D.eucalyptus.mycloud.example.com</code> , where <code>A-B-C-D</code> is the IP address (or addresses) assigned to your instance.</p><p>If you want to modify the subdomain that is reported as part of the instance DNS name, enter the following command:</p><pre><code>euctl cloud.vmstate.instance_subdomain=.custom-dns-subdomain
</code></pre><p>When this value is modified, the public and private DNS names reported for each instance will contain the specified custom DNS subdomain name, instead of the default value, which is <code>eucalyptus</code> . For example, if this value is set to <code>foobar</code> , the instance DNS names will appear as <code>euca-A-B-C-D.foobar.mycloud.example.com</code> .</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The code example above correctly begins with &ldquo;.&rdquo; before .</div><h2 id=enable-dns-delegation>Enable DNS Delegation</h2><p>DNS delegation allows you to forward DNS traffic for the Eucalyptus subdomain to the Eucalyptus CLC host. This host acts as a name server. This allows interruption-free access to Eucalyptus cloud services in the event of a failure. The CLC host is capable of mapping cloud host names to IP addresses of the CLC and UFS / OSG host machines.</p><p>For example, if the IP address of the CLC is <code>192.0.2.5</code> , and the IP address of Walrus is <code>192.0.2.6</code> , the host <code>compute.mycloud.example.com</code> resolves to <code>192.0.2.5</code> and <code>objectstorage.mycloud.example.com</code> resolves to <code>192.0.2.6</code> .</p><p>To enable DNS delegation:</p><p>Enter the following command on the CLC:</p><pre><code>euctl bootstrap.webservices.use_dns_delegation=true
</code></pre><h2 id=configure-the-master-dns-server>Configure the Master DNS Server</h2><p>Set up your master DNS server to delegate the Eucalyptus subdomain to the UFS host machines, which act as name servers.</p><p>The following example shows how the Linux name server <code>bind</code> is set up to delegate the Eucalyptus subdomain.</p><p>Open <em>/etc/named.conf</em> and set up the <code>example.com</code> zone. For example, your <em>/etc/named.conf</em> may look like the following:</p><pre><code>zone &quot;example.com&quot; IN {
	      type master;
	      file &quot;/etc/bind/db.example.com&quot;;
	      };
</code></pre><p>Create <em>/etc/bind/db.example.com</em> if it does not exist. If your master DNS is already set up for <code>example.com</code> , you will need to add a name server entry for UFS host machines. For example:</p><pre><code>$ORIGIN example.com.
$TTL 604800

@ IN    SOA ns1 admin.example.com 1 604800 86400 2419200 604800
        NS  ns1
ns1     A   MASTER.DNS.SERVER_IP
ufs1    A   UFS1_IP
mycloud NS  ufs1
</code></pre><p>After this, you will be able to resolve your instances&rsquo; public DNS names such as <code>euca-A-B-C-D.eucalyptus.mycloud.example.com</code> .</p><p>Restart the bind nameserver <code>service named restart</code> . Verify your setup by pointing <em>/etc/resolv.conf</em> on your client to your primary DNS server and attempt to resolve <code>compute.example.com</code> using ping or nslookup. It should return the IP address of a UFS host machine.</p><h2 id=advanced-dns-options>Advanced DNS Options</h2><p>Recursive lookups and split-horizon DNS are available in Eucalyptus .</p><p>To enable any of the DNS resolvers, set <code>dns.enabled</code> to <code>true</code> . To enable the recursive DNS resolver, set <code>dns.recursive.enabled</code> to <code>true</code> . To enable split-horizon DNS resolution for internal instance public DNS name queries, set <code>dns.split_horizon.enabled</code> to <code>true</code> .</p><h2 id=optional-configure-eucalyptus-dns-to-spoof-aws-endpoints>Optional: Configure Eucalyptus DNS to Spoof AWS Endpoints</h2><p>You can configure instances to use AWS region FQDNs for service endpoints by enabling DNS spoofing.</p><p>Set up a Eucalyptus cloud with Eucalyptus DNS and HTTPS endpoints. When creating CSR, make sure and add Subject Alternative Names for all the supported AWS services for the given region that’s being tested. For example:</p><pre><code>$ openssl req -in wildcard.c-06.autoqa.qa1.eucalyptus-systems.com.csr 
						-noout -text | less X509v3 Subject Alternative Name:
     DNS:ec2.us-east-1.amazonaws.com, DNS:autoscaling.us-east-1.amazonaws.com, 
     DNS:cloudformation.us-east-1.amazonaws.com, DNS:monitoring.us-east-1.amazonaws.com, 
     DNS:elasticloadbalancing.us-east-1.amazonaws.com, DNS:s3.amazonaws.com, 
     DNS:sts.us-east-1.amazonaws.com
</code></pre><p>Set DNS spoofing:</p><pre><code>[root@d-17 ~]#  euctl dns.spoof_regions --region euca-admin@future
dns.spoof_regions.enabled = true
dns.spoof_regions.region_name =
dns.spoof_regions.spoof_aws_default_regions = true
dns.spoof_regions.spoof_aws_regions = true
</code></pre><p>Launch an instance, and allow SSH access. SSH into the instance and install AWS CLI.</p><pre><code>ubuntu@euca-172-31-12-59:~$ sudo apt-get install -y python-pip
ubuntu@euca-172-31-12-59:~$ sudo -H pip install --upgrade pip
ubuntu@euca-172-31-12-59:~$ sudo -H pip install --upgrade awscli
</code></pre><p>Run <code>aws configure</code> and set access and secret key information if not using instance profile. Confirm AWS CLI works with HTTPS Eucalyptus service endpoint:</p><pre><code>ubuntu@euca-172-31-12-59:~$ aws --ca-bundle euca-ca-0.crt 
--endpoint-url https://ec2.c-06.autoqa.qa1.eucalyptus-systems.com/ ec2 describe-key-pairs
{
    &quot;KeyPairs&quot;: [
        {
            &quot;KeyName&quot;: &quot;devops-admin&quot;,
            &quot;KeyFingerprint&quot;: &quot;ee:4f:93:a8:87:8d:80:8d:2c:d6:d5:60:20:a3:2d:b2&quot;
        }
    ]
}
</code></pre><p>Test against AWS FQDN service endpoint that matches one of the SANs in the signed certificate:</p><pre><code>ubuntu@euca-172-31-12-59:~$ aws --ca-bundle euca-ca-0.crt 
--endpoint-url https://ec2.us-east-1.amazonaws.com ec2 describe-key-pairs{
    &quot;KeyPairs&quot;: [
        {
            &quot;KeyName&quot;: &quot;devops-admin&quot;,
            &quot;KeyFingerprint&quot;: &quot;ee:4f:93:a8:87:8d:80:8d:2c:d6:d5:60:20:a3:2d:b2&quot;
        }
    ]
}				
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-09d0cc0a79d201e09f5c9804c4c61cd3>4.7.2 - Create the Eucalyptus Cloud Administrator User</h1><p>After your cloud is running and DNS is functional, create a user and access key for day-to-day cloud administration.</p><h2 id=prerequisites>Prerequisites</h2><ul><li>cloud services must be installed and registered.</li><li>DNS must be configured.</li></ul><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>This is where you would begin using the admin role, if you want to use that feature.</div><h2 id=create-a-cloud-admin-user>Create a cloud admin user</h2><p>Eucalyptus admin tools and Euca2ools commands need configuration from <em>~/.euca</em> . If the directory does not yet exist, create it:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>mkdir ~/.euca
</span></span></code></pre></div><p>Choose a name for the new user and create it along with an access key:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euare-usercreate -wld DOMAIN USER &gt;~/.euca/FILE.ini
</span></span></code></pre></div><p>where:</p><ul><li><strong>DOMAIN</strong> must match the DNS domain for the cloud.</li><li><strong>USER</strong> is the name of the new admin user.</li><li><strong>FILE</strong> can be anything; we recommend a descriptive name that includes the user&rsquo;s name.</li></ul><p>This creates a file with a region name that matches that of your cloud&rsquo;s DNS domain; you can edit the file to change the region name if needed.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>This creates an admin user in the built-in <strong>eucalyptus</strong> account. The admin user has full control of all aspects of the cloud. For additional security, you might instead want to create a new account and grant it access to a more limited administration role.</div><p>Switch to the new admin user:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># eval `clcadmin-release-credentials`</span>
</span></span><span style=display:flex><span><span style=color:#8f5902;font-style:italic># export AWS_DEFAULT_REGION=REGION</span>
</span></span></code></pre></div><p>where:</p><ul><li><strong>REGION</strong> must match the region name from the previous step. By default, this is the same as the cloud&rsquo;s DNS domain.</li></ul><p>As long as this file exists in <em>~/.euca</em> , you can use it by repeating the <code>export</code> command above. These <code>euca2ools.ini</code> configuration files are a flexible means of managing cloud regions and users.</p><p>Alternatively you can configure the default region in the <strong>global</strong> section of your Euca2ools configuration:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># cat ~/.euca/global.ini</span>
</span></span><span style=display:flex><span><span style=color:#ce5c00;font-weight:700>[</span>global<span style=color:#ce5c00;font-weight:700>]</span>
</span></span><span style=display:flex><span>default-region <span style=color:#ce5c00;font-weight:700>=</span> REGION
</span></span></code></pre></div><p>setting the <strong>REGION</strong> to the one from the earlier step means you do not have to use <em>export</em> to select the region.</p><h2 id=user-impersonation>User impersonation</h2><p>The <strong>eucalyptus</strong> account can act as other accounts for administrative purposes. To act as the <em>admin</em> user in the <em>account-1</em> account run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># eval `clcadmin-impersonate-user -a account-1 -u admin`</span>
</span></span></code></pre></div><p>Impersonating an account allows you to view and modify resources for that account. For example, you can clean up resources in an account before deleting it.</p><p>To stop impersonating run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>clcadmin-release-credentials
</span></span></code></pre></div><h2 id=next-steps>Next steps</h2><p>The remainder of this guide assumes you have completed the above steps.</p><p>Use these credentials after this point.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-dc4447570e8060e614e4b8d90b23a14c>4.7.3 - Upload the Network Configuration</h1><p>This topic describes how to upload the network configuration created earlier in the installation process. To upload your networking configuration:</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>This step can only be run after getting your credentials in <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configure_runtime/credentials_admin_create/>Create the Eucalyptus Cloud Administrator User</a>.</div><p>Run the following command to upload the configuration file to the CLC (with valid Eucalyptus admin credentials):</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl cloud.network.network_configuration<span style=color:#ce5c00;font-weight:700>=</span>@/path/to/your/network_config_file
</span></span></code></pre></div><p>To review the existing network configuration run:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl  --dump --format<span style=color:#ce5c00;font-weight:700>=</span>raw cloud.network.network_configuration
</span></span></code></pre></div><p>When you use the Ansible playbook for deployment a network configuration file is available at <em>/etc/eucalyptus/network.yaml</em> on the CLC.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-fd3ae2688dc91115bc710364761b2ce5>4.7.4 - Configure Eucalyptus Storage</h1><h1 id=configure-storage>Configure Storage</h1><p>These are the types of storage available for your Eucalyptus cloud. Object storage Eucalyptus provides an AWS S3 compatible object storage service that provides users with web-based general purpose storage, designed to be scalable, reliable and inexpensive. You choose the object storage backend provider: Walrus or Ceph RGW. The Object Storage Gateway (OSG) provides access to objects via the backend provider you choose.</p><p>Block storage Eucalyptus provides an AWS EBS compatible block storage service that provides block storage for EC2 instances. Volumes can be created as needed and dynamically attached and detached to instances as required. EBS provides persistent data storage for instances: the volume, and the data on it, can exist beyond the lifetime of an instance. You choose the block storage backend provider for a deployment.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a6a6c7da8c6d5461dad3100d9ba3e31c>4.7.4.1 - Configure Block Storage</h1><h1 id=configure-block-storage>Configure Block Storage</h1><p>This topic describes how to configure block storage on the Storage Controller (SC) for the backend of your choice.</p><p>The Storage Controller (SC) provides functionality similar to the Amazon Elastic Block Store (Amazon EBS). The SC can interface with various storage systems. Eucalyptus block storage (EBS) exports storage volumes that can be attached to a VM and mounted or accessed as a raw block device. EBS volumes can persist past VM termination and are commonly used to store persistent data.</p><p>Eucalyptus provides the following open source (free) backend providers for the SC:</p><ul><li>Overlay, using the local file system</li><li>DAS-JBOD (just a bunch of disks)</li><li>Ceph</li></ul><p>You must configure the SC to use one of the backend provider options.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-aa18b8d819fd6a67cb70f4fa0d18328b>4.7.4.1.1 - Use Ceph-RBD</h1><h1 id=use-ceph-rbd>Use Ceph-RBD</h1><p>This topic describes how to configure Ceph-RBD as the block storage backend provider for the Storage Controller (SC).<strong>Prerequisites</strong></p><ul><li><p>Successful completion of all the install sections prior to this section.</p></li><li><p>The SC must be installed, registered, and running.</p></li><li><p>You must execute the steps below as a administrator.</p></li><li><p>You must have a functioning Ceph cluster.</p></li><li><p>Ceph user credentials with the following privileges are available to SCs and NCs (different user credentials can be used for the SCs and NCs).</p></li><li><p>Hypervisor support for Ceph-RBD on NCs. Node Controllers (NCs) are designed to communicate with the Ceph cluster via libvirt. This interaction requires a hypervisor that supports Ceph-RBD. See to satisfy this prerequisite.
<strong>To configure Ceph-RBD block storage for the zone, run the following commands on the CLC</strong> Configure the SC to use Ceph-RBD for EBS.</p><p>euctl ZONE.storage.blockstoragemanager=ceph-rbd</p></li></ul><p>The output of the command should be similar to:</p><pre><code>one.storage.blockstoragemanager=ceph-rbd
</code></pre><p>Verify that the property value is now <code>ceph-rbd</code> :</p><pre><code>euctl ZONE.storage.blockstoragemanager
</code></pre><p>Check the SC to be sure that it has transitioned out of the <code>BROKEN</code> state and is in the <code>NOTREADY</code> , <code>DISABLED</code> or <code>ENABLED</code> state before configuring the rest of the properties for the SC. The ceph-rbd provider will assume defaults for the following properties for the SC:</p><pre><code>euctl ZONE.storage.ceph
 
PROPERTY        one.storage.cephconfigfile  /etc/ceph/ceph.conf
DESCRIPTION     one.storage.cephconfigfile  Absolute path to Ceph configuration (ceph.conf) file. Default value is '/etc/ceph/ceph.conf'
 
PROPERTY        one.storage.cephkeyringfile /etc/ceph/ceph.client.eucalyptus.keyring
DESCRIPTION     one.storage.cephkeyringfile Absolute path to Ceph keyring (ceph.client.eucalyptus.keyring) file. Default value is '/etc/ceph/ceph.client.eucalyptus.keyring'
 
PROPERTY        one.storage.cephsnapshotpools       rbd
DESCRIPTION     one.storage.cephsnapshotpools       Ceph storage pool(s) made available to  for EBS snapshots. Use a comma separated list for configuring multiple pools. Default value is 'rbd'
 
PROPERTY        one.storage.cephuser        eucalyptus
DESCRIPTION     one.storage.cephuser        Ceph username employed by  operations. Default value is 'eucalyptus'
 
PROPERTY        one.storage.cephvolumepools rbd
DESCRIPTION     one.storage.cephvolumepools Ceph storage pool(s) made available to  for EBS volumes. Use a comma separated list for configuring multiple pools. Default value is 'rbd'
</code></pre><p>The following steps are optional if the default values do not work for your cloud: To set the Ceph username (the default value for Eucalyptus is &rsquo;eucalyptus&rsquo;):</p><pre><code>euctl ZONE.storage.cephuser=myuser
</code></pre><p>To set the absolute path to keyring file containing the key for the &rsquo;eucalyptus&rsquo; user (the default value is &lsquo;/etc/ceph/ceph.client.eucalyptus.keyring&rsquo;):</p><pre><code>euctl ZONE.storage.cephkeyringfile='/etc/ceph/ceph.client.myuser.keyring'
</code></pre><p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If cephuser was modified, ensure that cephkeyringfile is also updated with the location to the keyring for the specific cephuser:</div>To set the absolute path to ceph.conf file (default value is &lsquo;/etc/ceph/ceph.conf&rsquo;):</p><pre><code>euctl ZONE.storage.cephconfigfile=/path/to/ceph.conf
</code></pre><p>To change the comma-delimited list of Ceph pools assigned to Eucalyptus for managing EBS volumes (default value is &lsquo;rbd&rsquo;) :</p><pre><code>euctl ZONE.storage.cephvolumepools=rbd,myvolumes
</code></pre><p>To change the comma-delimited list of Ceph pools assigned to Eucalyptus for managing EBS snapshots (default value is &lsquo;rbd&rsquo;) :</p><pre><code>euctl ZONE.storage.cephsnapshotpools=mysnapshots
</code></pre><p>If you want to enable snapshot deltas for your Ceph backend:<div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Snapshot deltas are supported only on Ceph-RBD.</div></p><p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4></div>Verify that snapshots are enabled:</p><pre><code>euctl ZONE.storage.shouldtransfersnapshots=true
</code></pre><p>Set the maximum number of deltas to be created before creating a new full snapshot:</p><pre><code>euctl ZONE.storage.maxsnapshotdeltas=NON_ZERO_INTEGER
</code></pre><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>This variable applies to all Ceph volumes.</div><p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If you need to create a non-Ceph volume from a Ceph snapshot, this value would need to be set to zero (at least temporarily).</div>Every NC will assume the following defaults:</p><pre><code>CEPH_USER_NAME=&quot;eucalyptus&quot;
CEPH_KEYRING_PATH=&quot;/etc/ceph/ceph.client.eucalyptus.keyring&quot;
CEPH_CONFIG_PATH=&quot;/etc/ceph/ceph.conf&quot;
</code></pre><p>To override the above defaults, add/edit the following properties in the <code>/etc/eucalyptus/eucalyptus.conf</code> on the specific NC file:</p><pre><code>CEPH_USER_NAME=&quot;ceph-username-for-use-by-this-NC&quot;
CEPH_KEYRING_PATH=&quot;path-to-keyring-file-for-ceph-username&quot;
CEPH_CONFIG_PATH=&quot;path-to-ceph.conf-file&quot;
</code></pre><p>Repeat this step for every NC in the specific Eucalyptus zone. Your Ceph backend is now ready to use with Eucalyptus .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-30efcc5250832311a0363dcab5fce14e>4.7.4.1.1.1 - Configure Hypervisor Support for Ceph-RBD</h1><p>This topic describes how to configure the hypervisor for Ceph-RBD support.The following instructions will walk you through steps for verifying and or installing the required hypervisor for Ceph-RBD support. <strong>Repeat this process for every NC in the Eucalyptus zone</strong></p><p>Verify if <code>qemu-kvm</code> and <code>qemu-img</code> are already installed.</p><pre><code>rpm -q qemu-kvm qemu-img
</code></pre><p>Proceed to the preparing the RHEV qemu packages step if they are not installed.</p><p>Verify qemu support for the <code>ceph-rbd</code> driver.</p><pre><code>qemu-img --help
qemu-img version 0.12.1, Copyright (c) 2004-2008 Fabrice Bellard
...
Supported formats: raw cow qcow vdi vmdk cloop dmg bochs vpc vvfat qcow2 qed vhdx parallels nbd blkdebug host_cdrom 
host_floppy host_device file gluster gluster gluster gluster rbd
</code></pre><p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If &lsquo;rbd&rsquo; is listed as one of the supported formats, no further action is required; otherwise proceed to the next step.</div>If the <code>eucalyptus-node</code> service is running, terminate/stop all instances. After all instances are terminated, stop the eucalyptus-node service.</p><pre><code>systemctl stop eucalyptus-node.service
</code></pre><p>Prepare the RHEV qemu packages:</p><ul><li><p>If this NC is a RHEL system and the RHEV subscription to qemu packages is available, consult the RHEV package procedure to install the qemu-kvm-ev and qemu-img-ev packages. Blacklist the RHEV packages in the repository to ensure that packages from the RHEV repository are installed.</p></li><li><p>If this NC is a RHEL system and RHEV subscription to qemu packages is unavailable, built and maintained qemu-rhev packages may be used. These packages are available in the same yum repository as other packages. Note that using built RHEV packages voids the original RHEL support for the qemu packages.</p></li><li><p>If this NC is a non-RHEL (CentOS) system, -built and maintained qemu-rhev packages may be used. These packages are available in the same yum repository as other packages.
If you are <em>not</em> using the RHEV package procedure to install the <code>qemu-kvm-ev</code> and <code>qemu-img-ev</code> packages, install Eucalyptus -built RHEV packages: <code>qemu-kvm-ev</code> and <code>qemu-img-ev</code> , which can be found in the same yum repository as other Eucalyptus packages.</p><p>yum install qemu-kvm-ev qemu-img-ev</p></li></ul><p>Start the <code>libvirtd</code> service.</p><pre><code>systemctl start libvirtd.service
</code></pre><p>Verify <code>qemu</code> support for the <code>ceph-rbd</code> driver.</p><pre><code>qemu-img --help
qemu-img version 0.12.1, Copyright (c) 2004-2008 Fabrice Bellard
...
Supported formats: raw cow qcow vdi vmdk cloop dmg bochs vpc vvfat qcow2 qed vhdx parallels nbd blkdebug host_cdrom 
host_floppy host_device file gluster gluster gluster gluster rbd
</code></pre><p>Make sure the eucalyptus-node service is started.</p><pre><code>systemctl start eucalyptus-node.service
</code></pre><p>Your hypervisor is ready for Eucalyptus Ceph-RBD support. You are now ready to <a href=https://www.eucastack.io/docs/install_guide/eucalyptus/configure_runtime/config_storage/config_block_storage/config_storage_ceph_rbd/>configure Ceph-RBD</a> for Eucalyptus .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-3545c566a3fc5b961cdc7b265f1876ce>4.7.4.1.2 - About the BROKEN State</h1><p>This topic describes the initial state of the Storage Controller (SC) after you have registered it with the Cloud Controller (CLC).The SC automatically goes to the <code>broken</code> state after being registered with the CLC; it will remain in that state until you explicitly configure the SC by telling it which backend storage provider to use.</p><p>You can check the state of a storage controller by running <code>euserv-describe-services --expert</code> and note the state and status message of the SC(s). The output for an unconfigured SC looks something like this:</p><pre><code>SERVICE	storage        	ZONE1        	SC71           	BROKEN    	37  	http://192.168.51.71:8773/services/Storage	arn:euca:eucalyptus:ZONE1:storage:SC71/
SERVICEEVENT	6c1f7a0a-21c9-496c-bb79-23ddd5749222	arn:euca:eucalyptus:ZONE1:storage:SC71/
SERVICEEVENT	6c1f7a0a-21c9-496c-bb79-23ddd5749222	ERROR
SERVICEEVENT	6c1f7a0a-21c9-496c-bb79-23ddd5749222	Sun Nov 18 22:11:13 PST 2012
SERVICEEVENT	6c1f7a0a-21c9-496c-bb79-23ddd5749222	SC blockstorageamanger not configured. Found empty or unset manager(unset). Legal values are: das,overlay,ceph
</code></pre><p>Note the error above: <code>SC blockstoragemanager not configured. Found empty or unset manager(unset). Legal values are: das,overlay,ceph</code> .</p><p>This indicates that the SC is not yet configured. It can be configured by setting the <code>ZONE.storage.blockstoragemanager</code> property to &lsquo;das&rsquo;, &lsquo;overlay&rsquo;, or &lsquo;ceph&rsquo;.</p><p>You can verify that the configured SC block storage manager using:</p><pre><code>euctl ZONE.storage.blockstoragemanager
</code></pre><p>to show the current value.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-07723a85c687e2a440a2f0f6cefdfba9>4.7.4.1.3 - Use Direct Attached Storage (JBOD)</h1><p>This topic describes how to configure the DAS-JBOD as the block storage backend provider for the Storage Controller (SC).<strong>Prerequisites</strong></p><ul><li><p>Successful completion of all the install sections prior to this section.</p></li><li><p>The SC must be installed, registered, and running.</p></li><li><p>Direct Attached Storage requires that have enough space for locally cached snapshots.</p></li><li><p>You must execute the steps below as a administrator.
<strong>To configure DAS-JBOD block storage for the zone, run the following commands on the CLC</strong> Configure the SC to use the Direct Attached Storage for EBS.</p><p>euctl ZONE.storage.blockstoragemanager=das</p></li></ul><p>The output of the command should be similar to:</p><pre><code>one.storage.blockstoragemanager=das
</code></pre><p>Verify that the property value is now: &lsquo;das&rsquo;</p><pre><code>euctl ZONE.storage.blockstoragemanager
</code></pre><p>Set the DAS device name property. The device name can be either a raw device (/dev/sdX, for example), or the name of an existing Linux LVM volume group.</p><pre><code>euctl ZONE.storage.dasdevice=DEVICE_NAME
</code></pre><p>For example:</p><pre><code>euctl one.storage.dasdevice=/dev/sdb
</code></pre><p>Your DAS-JBOD backend is now ready to use with Eucalyptus .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8aef961027c14d30b9d6272cd4fd35d4>4.7.4.1.4 - Use the Overlay Local Filesystem</h1><p>This topic describes how to configure the local filesystem as the block storage backend provider for the Storage Controller (SC).<strong>Prerequisites</strong></p><ul><li>Successful completion of all the install sections prior to this section.</li><li>The SC must be installed, registered, and running.</li><li>The local filesystem must have enough space to hold volumes and snapshots created in the cloud.</li><li>You must execute the steps below as a administrator.
In this configuration the SC itself hosts the volume and snapshots for EBS and stores them as files on the local filesystem. It uses standard Linux iSCSI tools to serve the volumes to instances running on NCs.</li></ul><p><strong>To configure overlay block storage for the zone, run the following commands on the CLC</strong> Configure the SC to use the local filesystem for EBS.</p><pre><code>euctl ZONE.storage.blockstoragemanager=overlay 
</code></pre><p>The output of the command should be similar to:</p><pre><code>one.storage.blockstoragemanager=overlay
</code></pre><p>Verify that the property value is now: &lsquo;overlay&rsquo;</p><pre><code>euctl ZONE.storage.blockstoragemanager
</code></pre><p>Your local filesystem (overlay) backend is now ready to use with Eucalyptus .</p></div><div class=td-content style=page-break-before:always><h1 id=pg-25aafdcb9e624a1e783a00453ac2ce31>4.7.4.2 - Configure Object Storage</h1><p>This topic describes how to configure object storage on the Object Storage Gateway (OSG) for the backend of your choice. The OSG passes requests to object storage providers and talks to the persistence layer (DB) to authenticate requests. You can use Walrus, MinIO, or Ceph-RGW as the object storage provider.</p><ul><li><p><strong>Walrus</strong> - the default backend provider. It is a single-host Eucalyptus -integrated provider which provides basic object storage functionality for the small scale. Walrus is intended for light S3 usage.</p></li><li><p><strong>MinIO</strong> - a high performing scalable object storage provider. MinIO implements the S3 API which is used by the OSG, not directly by end users. Distributed MinIO provides protection against multiple node/drive failures and bit rot using erasure code.</p></li><li><p><strong>Ceph-RGW</strong> - an object storage interface built on top of Librados to provide applications with a RESTful gateway to Ceph Storage Clusters. Ceph-RGW uses the Ceph Object Gateway daemon (radosgw), which is a FastCGI module for interacting with a Ceph Storage Cluster. Since it provides interfaces compatible with OpenStack Swift and Amazon S3, the Ceph Object Gateway has its own user management. Ceph Object Gateway can store data in the same Ceph Storage Cluster used to store data from Ceph Filesystem clients or Ceph Block Device clients. The S3 and Swift APIs share a common namespace, so you may write data with one API and retrieve it with the other.</p></li></ul><p>You must configure the OSG to use one of the backend provider options.</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>If OSG has been registered but not yet properly configured, it will be listed in the state when listed with the euserv-describe-services command.</div><p>Example showing unconfigured <em>objectstorage</em>:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># euserv-describe-services --show-headers --filter service-type=objectstorage</span>
</span></span><span style=display:flex><span>SERVICE  TYPE              	ZONE    	NAME                   	  STATE	
</span></span><span style=display:flex><span>SERVICE  objectstorage      user-api-1  user-api-1.objectstorage  broken
</span></span></code></pre></div></div><div class=td-content style=page-break-before:always><h1 id=pg-06a4664ccf8870894a6bb96a526ff06f>4.7.4.2.1 - Use Ceph-RGW</h1><p>This topic describes how to configure Ceph Rados Gateway (RGW) as the backend for the Object Storage Gateway (OSG).</p><h2 id=prerequisites>Prerequisites</h2><ul><li>Successful completion of all the install sections prior to this section.</li><li>The UFS must be registered and enabled.</li><li>A Ceph storage cluster is available.</li><li>The ceph-radosgw service has been installed (on the UFS or any other host) and configured to use the Ceph storage cluster. recommends using civetweb with ceph-radosgw service. is a lightweight web server and is included in the ceph-radosgw installation. It is relatively easier to install and configure than the alternative option – a combination of Apache and Fastcgi modules.</li></ul><p>For more information on Ceph-RGW, see the <a href=http://docs.ceph.com/docs/master/radosgw/>Ceph-RGW documentation</a>.</p><h2 id=configure-ceph-rgw-object-storage>Configure Ceph-RGW object storage</h2><p>You must execute the steps below as a administrator.</p><p>Configure <strong>ceph-rgw</strong> as the storage provider using the <em>euctl</em> command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.providerclient<span style=color:#ce5c00;font-weight:700>=</span>ceph-rgw
</span></span></code></pre></div><p>Configure <em>objectstorage.s3provider.s3endpoint</em> to the <strong>ip:port</strong> of the host running the ceph-radosgw service:</p><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>Depending on the front end web server used by ceph-radosgw service, the default port is 80 for apache and 7480 for civetweb.</div><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.s3provider.s3endpoint<span style=color:#ce5c00;font-weight:700>=</span>&lt;radosgw-host-ip&gt;:&lt;radosgw-webserver-port&gt;
</span></span></code></pre></div><p>Configure <em>objectstorage.s3provider.s3accesskey</em> and <em>objectstorage.s3provider.s3secretkey</em> with the radosgw user credentials:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.s3provider.s3accesskey<span style=color:#ce5c00;font-weight:700>=</span>&lt;radosgw-user-accesskey&gt;
</span></span><span style=display:flex><span>euctl objectstorage.s3provider.s3secretkey<span style=color:#ce5c00;font-weight:700>=</span>&lt;radosgw-user-secretkey&gt;
</span></span></code></pre></div><p>The Ceph-RGW backend and OSG are now ready for production.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-84f727ca46a827f083dac6dafc1dba25>4.7.4.2.2 - Use MinIO Backend</h1><p>This topic describes how to configure MinIO as the object storage backend provider for the Object Storage Gateway (OSG).</p><h2 id=prerequisites>Prerequisites</h2><ul><li>The UFS must be registered and enabled.</li><li>Install and start MinIO</li></ul><p>For more information on MinIO installation and configuration see the <a href=https://docs.min.io/>MinIO Server Documentation</a></p><h2 id=to-configure-minio-object-storage>To configure MinIO object storage</h2><p>You must execute the steps below as a administrator.</p><p>Configure <strong>minio</strong> as the storage provider using the <em>euctl</em> command:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.providerclient<span style=color:#ce5c00;font-weight:700>=</span>minio
</span></span></code></pre></div><p>Configure <em>objectstorage.s3provider.s3endpoint</em> to the <strong>ip:port</strong> of a host running the minio server:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.s3provider.s3endpoint<span style=color:#ce5c00;font-weight:700>=</span>&lt;minio-host-ip&gt;:&lt;minio-port&gt;
</span></span></code></pre></div><div class="alert alert-success" role=alert><h4 class=alert-heading>Note</h4>The default port for MinIO is 9000</div><p>Configure <em>objectstorage.s3provider.s3accesskey</em> and <em>objectstorage.s3provider.s3secretkey</em> with credentials for minio:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.s3provider.s3accesskey<span style=color:#ce5c00;font-weight:700>=</span>&lt;minio-accesskey&gt;
</span></span><span style=display:flex><span>euctl objectstorage.s3provider.s3secretkey<span style=color:#ce5c00;font-weight:700>=</span>&lt;minio-secretkey&gt;
</span></span></code></pre></div><p>Configure the expected response code for minio:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.s3provider.s3endpointheadresponse<span style=color:#ce5c00;font-weight:700>=</span><span style=color:#0000cf;font-weight:700>400</span>
</span></span></code></pre></div><p>The MinIO backend and OSG are now ready for production.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-bfe6a73803221ee955acb39011736fbe>4.7.4.2.3 - Use Walrus Backend</h1><p>This topic describes how to configure Walrus as the object storage backend provider for the Object Storage Gateway (OSG).</p><h2 id=prerequisites>Prerequisites</h2><ul><li>Successful completion of all the install sections prior to this section.</li><li>The UFS must be registered and enabled.</li></ul><h2 id=to-configure-walrus-object-storage>To configure Walrus object storage</h2><p>You must execute the steps below as a administrator.</p><p>Configure <strong>walrus</strong> as the storage provider using the <em>euctl</em> command.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euctl objectstorage.providerclient<span style=color:#ce5c00;font-weight:700>=</span>walrus
</span></span></code></pre></div><p>Check that the OSG is enabled.</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>euserv-describe-services
</span></span></code></pre></div><p>If the state appears as <strong>disabled</strong> or <strong>broken</strong> , check the cloud-*.log files in the <em>/var/log/eucalyptus</em> directory. A <strong>disabled</strong> state generally indicates that there is a problem with your network or credentials. See <a href=https://www.eucastack.io/docs/admin_guide/ops_oview/ops_ts/ts_logs/>Log File Location and Content</a> for more information.</p><p>The Walrus backend and OSG are now ready for production.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-88c36c1a825c683df6b9c36b64b2ad63>4.7.5 - Install and Configure the Imaging Service</h1><p>The Eucalyptus Imaging Service, introduced in Eucalyptus 4.0, makes it easier to deploy EBS images in your Eucalyptus cloud and automates many of the labor-intensive processes required for uploading data into EBS images.</p><p>The Eucalyptus Imaging Service is implemented as a system-controlled &ldquo;worker&rdquo; virtual machine that is monitored and controlled via Auto Scaling. Once the Imaging Service is configured, the Imaging Service VM will be started automatically upon the first request that requires it: such as an EBS volume ingress. Specifically, in this release of Eucalyptus , these are the usage scenarios for the Eucalyptus Imaging Service:</p><ul><li><strong>Importing a raw disk image as a volume:</strong> If you have a raw disk image (containing either a data partition or a full operating system with a boot record, e.g., an HVM image), you can use the Imaging Service to import this into your cloud as a volume. This is accomplished with the <code>euca-import-volume</code> command. If the volume was populated with a bootable disk, that volume can be snapshotted and registered as an image.</li><li><strong>Importing a raw disk image as an instance:</strong> If you have a raw disk image containing a bootable operating system, you can import this disk image into as an instance: the Imaging Service automatically creates a volume, registers the image, and launches an instance from the image. This is accomplished with the <code>euca-import-instance</code> command, which has options for specifying the instance type and the SSH key for the instance to use.</li></ul><h2 id=install-and-register-the-imaging-worker-image>Install and Register the Imaging Worker Image</h2><p>Eucalyptus provides a command-line tool for installing and registering the Imaging Worker image. Once you have run the tool, the Imaging Worker will be ready to use.Run the following commands on the machine where you installed the <code>eucalyptus-service-image</code> RPM package (it will set the <code>imaging.imaging_worker_emi</code> property to the newly created EMI of the imaging worker):</p><pre><code>esi-install-image --region localhost --install-default
</code></pre><p>Consider setting the <code>imaging.imaging_worker_keyname</code> property to an SSH keyname (previously created with the <code>euca-create-keypair</code> command), so that you can perform troubleshooting inside the Imaging Worker instance, if necessary:</p><pre><code>euctl services.imaging.worker.keyname=mykey
</code></pre><h2 id=managing-the-imaging-worker-instance>Managing the Imaging Worker Instance</h2><p>Eucalyptus automatically starts Imaging Worker instances when there are tasks for workers to perform.The cloud administrator can list the running Imaging Worker instances, if any, by running the command:</p><pre><code>euca-describe-instances --filter tag-value=euca-internal-imaging-workers
</code></pre><p>To delete / stop the imaging worker:</p><pre><code>esi-manage-stack -a delete imaging
</code></pre><p>To create / start the imaging worker:</p><pre><code>esi-manage-stack -a create imaging
</code></pre><p>Consider setting the <code>imaging.imaging_worker_instance_type</code> property to an Instance Type with enough ephemeral disk to convert any of your paravirtual images. The Imaging Worker root filesystem takes up about 2GB, so the maximum paravirtual image that the Imaging Worker will be able to convert is the disk allocation of the Instance Type minus 2GBs.</p><pre><code>euctl services.imaging.worker.instance_type=m3.xlarge
</code></pre><h2 id=troubleshooting-imaging-worker>Troubleshooting Imaging Worker</h2><p>If the Imaging Worker is configured correctly, users will be able to import data into EBS volumes with <code>euca-import-*</code> commands, and paravirtual EMIs will run as instances. In some cases, though, paravirtual images may fail to convert (e.g., due to intermittent network failures or a network setup that doesn&rsquo;t allow the Imaging Worker to communicate with the CLC), leaving the images in a special state. To troubleshoot:If the Imaging Worker Instance Type does not provide sufficient disk space for converting all paravirtual images, the administrator may have to change the Instance Type used by the Imaging Worker. After changing the instance type, the Imaging Worker instance should be restarted by terminating the old Imaging Worker instance:</p><pre><code>euctl services.imaging.worker.instance_type=m2.2xlarge
euca-terminate-instances $(euca-describe-instances --filter tag-value=euca-internal-imaging-workers | grep INSTANCE | cut -f 2)
</code></pre><p>If the status of the conversion operation is &lsquo;Image conversion failed&rsquo;, but the image is marked as &lsquo;available&rsquo; (in the output of euca-describe-images), the conversion can be retried by running the EMI again:</p><pre><code>euca-run-instances ...
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-ebb91e7b9d56062f2a00522894fe0965>4.7.6 - Configure the Load Balancer</h1><h2 id=install-and-register-the-load-balancer-image>Install and Register the Load Balancer Image</h2><p>Eucalyptus provides a tool for installing and registering the Load Balancer image. Once you have run the tool, your Load Balancer will be ready to use.</p><p>Run the following commands on the machine where you installed the <code>eucalyptus-service-image</code> RPM package (it will set the <code>imaging.imaging_worker_emi</code> property to the newly created EMI of the imaging worker):</p><pre><code>esi-install-image --install-default
</code></pre><h2 id=verify-load-balancer-configuration>Verify Load Balancer Configuration</h2><p>If you would like to verify that Load Balancer support is enabled you can list installed Load Balancers. The currently active Load Balancer will be listed as enabled. If no Load Balancers are listed, or none are marked as enabled, then your Load Balancer support has not been configured properly.Run the following command to list installed Load Balancer images:</p><pre><code>esi-describe-images
</code></pre><p>This will produce output similar to the followin:</p><pre><code>SERVICE     VERSION  ACTIVE     IMAGE      INSTANCES
    imaging       2.2      *     emi-573925e5      0
 loadbalancing    2.2      *     emi-573925e5      0
    database      2.2      *     emi-573925e5      0
</code></pre><p>You can also check the enabled Load Balancer EMI with:</p><pre><code>euctl services.loadbalancing.worker.image
</code></pre><p>If you need to manually set the enabled Load Balancer EMI use:</p><pre><code>euctl services.loadbalancing.worker.image=emi-12345678
</code></pre></div><div class=td-content style=page-break-before:always><h1 id=pg-d2c8e2a6f2f469cba2014a65b5ab8768>4.7.7 - Configure Node Controller</h1><p>On some Linux installations, a sufficiently large amount of local disk activity can slow down process scheduling. This can cause other operations (e.g., network communication and instance provisioning) appear to stall. Examples of disk-intensive operations include preparing disk images for launch and creating ephemeral storage.</p><ol><li>Log in to an NC server and open the <em>/etc/eucalyptus/eucalyptus.conf</em> file.</li><li>Change the <code>CONCURRENT_DISK_OPS</code> parameter to the number of disk-intensive operations you want the NC to perform at once.<ol><li>Set <code>CONCURRENT_DISK_OPS</code> to 1 to serialize all disk-intensive operations. Or &mldr;</li><li>Set it to a higher number to increase the amount of disk-intensive operations the NC will perform in parallel.</li></ol></li></ol></div><div class=td-content style=page-break-before:always><h1 id=pg-18cc942116b7be0a5dd971348caeb9f8>5 - Client Installation</h1><p>The AWS CLI and Euca2ools are two command line interfaces that work well with Eucalyptus. See the relevant section for instructions to install each client.</p></div><div class=td-content><h1 id=pg-8cea5def468485a152ffc86adafe42ca>5.1 - AWS CLI Installation</h1><p>The AWS CLI is the official client for AWS. The CentOS and RHEL 7 official repositories provide a packaged AWS CLI version 1 that works well with Eucalyptus.</p><p>To allow easy use of the AWS CLI with Eucalyptus a plug-in is provided that understands how to access Eucalyptus services.</p><h2 id=install>Install</h2><p>To install the Eucalyptus plug-in a Eucalyptus YUM repository must first be enabled, either the release repository:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install https://downloads.eucalyptus.cloud/software/eucalyptus/5/rhel/7/x86_64/eucalyptus-release-5-1.11.as.el7.noarch.rpm
</span></span></code></pre></div><p>or the master repository for the latest nightly build:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install https://downloads.eucalyptus.cloud/software/eucalyptus/master/rhel/7/x86_64/eucalyptus-release-5-1.15.as.el7.noarch.rpm
</span></span></code></pre></div><p>Once a repository is configured, install the plugin and client:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install eucalyptus-awscli-plugin
</span></span></code></pre></div><p>Which will install the plug-in and version 1 of the AWS CLI.</p><h2 id=configuration>Configuration</h2><p>AWS provides general instructions on <a href=https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html>Configuring the AWS CLI</a> which includes configuration for credentials. This section covers Eucalyptus plugin specific configuration.</p><p>An example configuration for the AWS CLI is:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#8f5902;font-style:italic># cat .aws/config </span>
</span></span><span style=display:flex><span><span style=color:#ce5c00;font-weight:700>[</span>plugins<span style=color:#ce5c00;font-weight:700>]</span>
</span></span><span style=display:flex><span><span style=color:#000>eucalyptus</span> <span style=color:#ce5c00;font-weight:700>=</span> awscli_plugin_eucalyptus
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#ce5c00;font-weight:700>[</span>default<span style=color:#ce5c00;font-weight:700>]</span>
</span></span><span style=display:flex><span><span style=color:#000>ufshost</span> <span style=color:#ce5c00;font-weight:700>=</span> mycloud.example.com
</span></span><span style=display:flex><span><span style=color:#000>ufsport</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#0000cf;font-weight:700>8773</span>
</span></span><span style=display:flex><span><span style=color:#000>verify_ssl</span> <span style=color:#ce5c00;font-weight:700>=</span> yes
</span></span><span style=display:flex><span><span style=color:#000>output</span> <span style=color:#ce5c00;font-weight:700>=</span> text
</span></span><span style=display:flex><span><span style=color:#000>region</span> <span style=color:#ce5c00;font-weight:700>=</span> eucalyptus
</span></span></code></pre></div><p>The configuration enables the plugin and sets the <em>ufshost</em> and <em>ufsport</em> to enable Eucalyptus service endpoints to be derived.</p><p>If your cloud does not have a valid HTTPS certificate then you will need to change <em>verify_ssl</em> to <code>no</code>, but note that this is less secure.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-a6359d685c4cda87190983e9d9228cb1>5.2 - Euca2ools Standalone Installation</h1><p>Euca2ools is the Eucalyptus command line interface for interacting with Eucalyptus. This topic discusses how to perform a standalone installation of Euca2ools. If you&rsquo;re running recent versions of Fedora, Debian, or Ubuntu, you can install Euca2ools using <em>yum</em> or <em>apt</em>.</p><p>If you&rsquo;re running RHEL/CentOS, you can use the following instructions to install Euca2ools.</p><p>To perform a standalone installation of Euca2ools on RHEL/CentOS:</p><p>Configure the EPEL package repository:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install epel-release
</span></span></code></pre></div><p>Configure the Euca2ools package repository:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install http://downloads.eucalyptus.cloud/software/euca2ools/3.4/rhel/7/x86_64/euca2ools-release-3.4-2.2.as.el7.noarch.rpm
</span></span></code></pre></div><p>Install Euca2ools:</p><div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>yum install euca2ools
</span></span></code></pre></div><p>You&rsquo;ve now performed a standalone installation of Euca2ools.</p></div><div class=td-content style=page-break-before:always><h1 id=pg-8515c0c3c3e0fe7882713abf9dd756c5>6 - Find More Information</h1><p>This topic explains what to do once you have installed Eucalyptus, including further reading and other resources for understanding your cloud.</p><h2 id=read-more>Read More</h2><p>Eucalyptus has the following guides to help you with more information:</p><ul><li>The <a href=https://www.eucastack.io/docs/admin_guide/>Administration Guide</a> details ways to manage your Eucalyptus deployment. Refer to this guide to learn more about managing your Eucalyptus services, like the Cloud Controller; and resources, like instances and images.</li><li>The <a href=https://www.eucastack.io/docs/iam_guide/>Identity and Access Management (IAM) Guide</a> provides information to help you securely control access to services and resources for your Eucalyptus cloud users. Refer to this guide to learn more about managing identities, authentication and access control best practices, and specifically managing your users and groups.</li><li>The <a href=https://www.eucastack.io/docs/user_guide/>User Guide</a> details ways to use Eucalyptus for your computing and storage needs. Refer to this guide to learn more about getting and using euca2ools, creating images, running instances, and using dynamic block storage devices.</li><li>The <a href=https://www.eucastack.io/docs/image_guide/>Image Management Guide</a> describes how to create and manage images for your cloud.</li></ul></div></main></div></div><footer class="bg-dark py-5 row d-print-none"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Community forums" aria-label="Community forums"><a class=text-white target=_blank rel=noopener href=https://github.com/orgs/eucastack/discussions aria-label="Community forums"><i class="fa fa-comments"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/eucastack aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow"><a class=text-white target=_blank rel=noopener href=https://stackoverflow.com/questions/tagged/eucastack aria-label="Stack Overflow"><i class="fab fa-stack-overflow"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/eucastack aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Discord aria-label=Discord><a class=text-white target=_blank rel=noopener href=https://discord.gg/rZfweFv2dM aria-label=Discord><i class="fab fa-discord"></i></a></li></ul></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 EucaStack All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></small></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.c5fabd07bf74a61523c3b0406527237220f5cc80a23a9ae709f194b46828e68f.js integrity="sha256-xfq9B790phUjw7BAZScjciD1zICiOprnCfGUtGgo5o8=" crossorigin=anonymous></script></body></html>